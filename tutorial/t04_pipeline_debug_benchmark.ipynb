{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Pipeline debugging and benchmarking\n",
    "___\n",
    "When creating your own end-to-end deep learning workflow, things may go wrong anywhere along the way. You've probably experienced it... That's why it's very important to __access the data after the pipeline__ and examine the correctness of pipeline operations and preprocessing. Furthermore, in some cases, the pipeline may be too slow to keep the GPU busy. Users may need to __benchmark the pipeline speed__ to decide whether to move some operations to GPU or not.\n",
    "\n",
    "In this tutorial, we are going to show you how to access pipeline results and do pipeline benchmarking. We will use the same pipeline as in tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastestimator as fe\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define the pipeline *(same as tutorial 3)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image data is generated in /tmp/.fe/Mnist\n"
     ]
    }
   ],
   "source": [
    "from fastestimator.dataset.mnist import load_data\n",
    "from fastestimator.op import NumpyOp\n",
    "from fastestimator.util import RecordWriter\n",
    "from fastestimator.op.numpyop import ImageReader\n",
    "from fastestimator.op.tensorop import Augmentation2D\n",
    "from fastestimator.op import TensorOp\n",
    "\n",
    "# Create Rescale and Resize custom ops\n",
    "class Rescale(NumpyOp):\n",
    "    def forward(self, data, state):\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "\n",
    "class Resize(TensorOp):\n",
    "    def __init__(self, inputs, outputs, size):\n",
    "        super().__init__(inputs=inputs, outputs=outputs)\n",
    "        self.size = size\n",
    "    \n",
    "    def forward(self, data, state):\n",
    "        data = tf.image.resize(data, self.size)\n",
    "        return data\n",
    "\n",
    "# Load data\n",
    "train_csv, eval_csv, data_path = load_data()\n",
    "\n",
    "print(\"image data is generated in {}\".format(data_path))\n",
    "\n",
    "# Create RecordWriter\n",
    "writer = RecordWriter(save_dir=os.path.join(data_path, \"FEdata\"),\n",
    "                         train_data=train_csv,\n",
    "                         validation_data=eval_csv,\n",
    "                         ops=[ImageReader(inputs=\"x\", parent_path=data_path, grey_scale=True), \n",
    "                              Rescale(outputs=\"x\")])\n",
    "# Create Pipeline\n",
    "pipeline = fe.Pipeline(data=writer,\n",
    "                       batch_size=32,\n",
    "                       ops=[Resize(inputs=\"x\", size=(30, 30), outputs=\"x\"),\n",
    "                            Augmentation2D(outputs=\"x\", mode=\"train\", rotation_range=15)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Access the pipeline results\n",
    "\n",
    "`pipeline.show_results` is built for accessing the pipeline data.  \n",
    "For example, if users want to access single batch of pipeline data on epoch 0 during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator: Reading non-empty directory: /tmp/.fe/Mnist/FEdata\n",
      "FastEstimator: Found 60000 examples for train in /tmp/.fe/Mnist/FEdata/train_summary0.json\n",
      "FastEstimator: Found 10000 examples for eval in /tmp/.fe/Mnist/FEdata/eval_summary0.json\n",
      "shape of feature x is (32, 30, 30, 1)\n",
      "shape of feature y is (32,)\n"
     ]
    }
   ],
   "source": [
    "# Use show_results by specifying the epoch, mode and step (batch)\n",
    "result = pipeline.show_results(current_epoch=0, mode=\"train\", num_steps=1)\n",
    "\n",
    "# Isolate x and y from result\n",
    "x = result[0][\"x\"]\n",
    "y = result[0][\"y\"]\n",
    "print(\"shape of feature x is {}\".format(x.shape))\n",
    "print(\"shape of feature y is {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth label is 8\n",
      "ground truth label is 1\n",
      "ground truth label is 9\n",
      "ground truth label is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Display 4 examples of data after Pipeline\n",
    "fig, axes = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    axes[i].axis('off')\n",
    "    axes[i].imshow(np.squeeze(x[i]), cmap='gray')\n",
    "    print(\"ground truth label is {}\".format(y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Benchmark pipeline speed\n",
    "\n",
    "`pipeline.benchmark` can be used to benchmark the pipeline speed.  \n",
    "For example, if users want to benchmark on epoch 0 during training for 2000 steps (batches):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator: Reading non-empty directory: /tmp/.fe/Mnist/FEdata\n",
      "FastEstimator: Found 60000 examples for train in /tmp/.fe/Mnist/FEdata/train_summary0.json\n",
      "FastEstimator: Found 10000 examples for eval in /tmp/.fe/Mnist/FEdata/eval_summary0.json\n",
      "FastEstimator: Step: 100, Epoch: 0, Batch Size 32, Example/sec 27125.30\n",
      "FastEstimator: Step: 200, Epoch: 0, Batch Size 32, Example/sec 27397.79\n",
      "FastEstimator: Step: 300, Epoch: 0, Batch Size 32, Example/sec 27347.61\n",
      "FastEstimator: Step: 400, Epoch: 0, Batch Size 32, Example/sec 27330.95\n",
      "FastEstimator: Step: 500, Epoch: 0, Batch Size 32, Example/sec 27346.13\n",
      "FastEstimator: Step: 600, Epoch: 0, Batch Size 32, Example/sec 27343.98\n",
      "FastEstimator: Step: 700, Epoch: 0, Batch Size 32, Example/sec 27004.02\n",
      "FastEstimator: Step: 800, Epoch: 0, Batch Size 32, Example/sec 27087.50\n",
      "FastEstimator: Step: 900, Epoch: 0, Batch Size 32, Example/sec 26587.90\n",
      "FastEstimator: Step: 1000, Epoch: 0, Batch Size 32, Example/sec 27395.27\n",
      "FastEstimator: Step: 1100, Epoch: 0, Batch Size 32, Example/sec 26832.51\n",
      "FastEstimator: Step: 1200, Epoch: 0, Batch Size 32, Example/sec 26723.64\n",
      "FastEstimator: Step: 1300, Epoch: 0, Batch Size 32, Example/sec 26315.49\n",
      "FastEstimator: Step: 1400, Epoch: 0, Batch Size 32, Example/sec 27077.04\n",
      "FastEstimator: Step: 1500, Epoch: 0, Batch Size 32, Example/sec 26629.48\n"
     ]
    }
   ],
   "source": [
    "# You just have to specify the epoch, mode, and number of batches\n",
    "pipeline.benchmark(current_epoch=0,mode=\"train\", num_steps=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
