{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Operator\n",
    "\n",
    "In FastEstimator, the most important concept is `Operator`, which is used extensively in `RecordWriter`, `Pipeline` and `Network`. In this tutorial, we're going to talk about everything you need to know about `Operator`.\n",
    "\n",
    "Let's start with a short version: `Operator` is a class that works like a function, it is used in FastEstimator for constructing workflow graphs.\n",
    "\n",
    "As we all know, a python function has 3 compoents: input variable(s), transformation logics and output variable(s). Similarly, an `Operator` has 3 parts: input key(s), transformation fuction and output key(s). \n",
    "\n",
    "Now you may think: \"`Operator` and function are almost the same, what's different between them? why do we need it?\"\n",
    "\n",
    "The difference is: function uses variable whereas `Operator` uses keys (which is a representation of variable). The purpose of `Operator` is to allow users to construct a graph when variables are not created yet. In FastEstimator, we take care of the variable creation, routing and management such that users can have a good sleep at night.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Operator works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our data is in a dictionary format with key-value pairs, and an `Operator` named `Add_one` which add 1 to input key is given:\n",
    "```python\n",
    "data = {\"x\":1, \"y\":2}\n",
    "```\n",
    "if we want to add 1 to the value associated with key `x`, we can simply do:\n",
    "\n",
    "```python\n",
    "Add_one(inputs=\"x\", outputs=\"x\")\n",
    "```\n",
    "At run time, what the operator will do is:\n",
    "\n",
    "1. take the value of the input key 'x' from the data dictionary\n",
    "2. apply transformation functions to the value\n",
    "3. write the output value to the data dictionary with output key 'x'\n",
    "\n",
    "As a result, the data will become:\n",
    "```python\n",
    "{\"x\":2, \"y\":2}\n",
    "```\n",
    "\n",
    "Now let's add 1 to the value of `x` again and write the output to a new key `z`:\n",
    "```python\n",
    "\n",
    "Add_one(inputs=\"x\", outputs=\"z\")\n",
    "```\n",
    "data then becomes:\n",
    "```python\n",
    "{\"x\":2, \"y\":2, \"z\":3}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to express Operator connections in FastEstimator\n",
    "\n",
    "`Operator` can take multiple inputs and produce multiple outputs. One can see the true power of `Operator` when combining them in a sequence. The Figure below lists several examples of graph topologies enabled by lists of `Operator`. We will talk about `Schedule` in detail in future tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Ops.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are different types of Operators?\n",
    "\n",
    "On the implementation level, there are two types of `Operators` that every operator class inherits: `NumpyOp` and `TensorOp`. \n",
    "\n",
    "`NumpyOp` is used in the `ops` argument of `RecordWriter` only. Users can use any library inside the transformation function to calculate output. For example, users can call numpy, cv2, scipy functions etc. \n",
    "\n",
    "`TensorOp` is used in the `ops` argument of `Pipeline` and `Network`. Users are restricted to use tensor graph to construct the output. For example, the transformation logic has to be written in tensorfloew graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Operator is defined?\n",
    "\n",
    "An `Operator` is defined like this:\n",
    "\n",
    "```python\n",
    "class Operator:\n",
    "    def __init__(self, inputs=None, outputs=None, mode=None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        return data\n",
    "```\n",
    "\n",
    "where:\n",
    " * `inputs` and `outputs` are the keys for input and outputs of `forward` function. \n",
    " * `mode` is the execution mode (\"train\", \"eval\") that the Operator is active for. mode can be a string (like \"train\") or a list of string (like [\"train\", \"eval\"]). If mode is None, then it means Operator will be active for all scenarios.\n",
    " \n",
    "If there are multiple inputs/outputs in `forward` function, `inputs` and `outputs` can be a list or tuple, the `forward` function's input/output variable `data` will have the same data type. For example, if we need `AddOne` to take multiple inputs:\n",
    "\n",
    "```python\n",
    "\n",
    "#assume dictionary is {\"x\":1, \"y\":2}\n",
    "\n",
    "AddOne(inputs=\"x\") #the data in forward function is 1\n",
    "\n",
    "AddOne(inputs=[\"x\", \"y\"]) #the data in forward function is [1,2]\n",
    "\n",
    "AddOne(inputs=(\"x\", \"y\")) #the data in forward function is (1,2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator demo in FastEstimator\n",
    "\n",
    "Next we will illustrate the usage of `Operator` in an end-to-end deep learning task.  Let's start with the task in tutorial 2 and build more complex logics using `Operator`.\n",
    "\n",
    "Let's first generate some in-disk data images and csv files for later usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.mnist import load_data\n",
    "\n",
    "train_csv, eval_csv, data_path = load_data()\n",
    "\n",
    "print(\"image data is generated in {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 0: RecordWriter(use prebuilt Op and Custom Op)\n",
    "\n",
    "In this task, when the csv files and trainig images are provided in-disk, we want to do two preprocessing steps upfront:\n",
    "\n",
    "1. read the image (in grey scale) and label. (we will use the pre-built `ImageReader` Operator in FastEstimator)\n",
    "2. resale the image pixel value range, from [0, 255] to [-1, 1]. (We will customize an Operator to achieve this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.util.op import NumpyOp\n",
    "from fastestimator.record.preprocess import ImageReader\n",
    "import fastestimator as fe\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Rescale(NumpyOp):\n",
    "    def forward(self, data, state):\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "\n",
    "writer = fe.RecordWriter(save_dir=os.path.join(data_path, \"FEdata\"),\n",
    "                         train_data=train_csv,\n",
    "                         validation_data=eval_csv,\n",
    "                         ops=[ImageReader(inputs=\"x\", parent_path=data_path, grey_scale=True), \n",
    "                              Rescale(outputs=\"x\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the ops above, `ImageReader` does not have outputs and `Rescale` does not have inputs. This is because in FastEstimator, if the input of next operator uses the output of previous operator, then there is no need to read/write the data from/to the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: Pipeline: (use prebuilt Op and Custom Op)\n",
    "\n",
    "As mentioned before, `Pipeline` is responsible for real-time preprocessing during the training (such as augmentation).\n",
    "let's do the following preprocessing during training for each batch:\n",
    "1. Resize the imge to (30,30), we are going to customize this operation.\n",
    "2. Augment the image (rotation -15 to +15 degree), we are going to use prebuilt operator for it. \n",
    "\n",
    "Some may argue that `Resize` can be done upfront in `RecordWriter`, which this is true indeed.  But sometimes doing resize in the training may have some benefits, for example, we can save disk space by storing 28x28 data instead of 30x30.  It is up to the user to choose based on specific usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.pipeline.augmentation import Augmentation2D\n",
    "from fastestimator.util.op import TensorOp\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Resize(TensorOp):\n",
    "    def __init__(self, inputs, outputs, size):\n",
    "        super().__init__(inputs=inputs, outputs=outputs)\n",
    "        self.size = size\n",
    "    \n",
    "    def forward(self, data, state):\n",
    "        data = tf.image.resize(data, self.size)\n",
    "        return data\n",
    "\n",
    "pipeline = fe.Pipeline(data=writer,\n",
    "                       batch_size=32,\n",
    "                       ops=[Resize(inputs=\"x\", size=(30, 30), outputs=\"x\"),\n",
    "                            Augmentation2D(outputs=\"x\", mode=\"train\", rotation_range=15)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: Network: (use prebuilt Op and Custom Op)\n",
    "\n",
    "Network is responsible for differentiable executions, here let's do the following:\n",
    "1. feed the augmentated image to the network and get the predicted score\n",
    "2. scale the predicted score 10 times and write to a new key (this is only for demo purpose, it has no actual usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.architecture import LeNet\n",
    "from fastestimator.network.model import FEModel\n",
    "from fastestimator.network.model import ModelOp\n",
    "from fastestimator.network.loss import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "class Scale(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        data = data * 10\n",
    "        return data\n",
    "\n",
    "model = FEModel(model_def=lambda: LeNet(input_shape=(30, 30, 1)), model_name=\"lenet\", optimizer=\"adam\", loss_name=\"loss\")\n",
    "network = fe.Network(ops=[ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"), \n",
    "                          SparseCategoricalCrossentropy(y_pred=\"y_pred\", y_true=\"y\", outputs=\"loss\"),\n",
    "                          Scale(inputs=\"y_pred\", outputs=\"y_pred_scaled\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: Estimator (same as tutorial 2, nothing special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(network=network, pipeline=pipeline, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
