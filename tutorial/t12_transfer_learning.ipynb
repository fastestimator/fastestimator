{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 12: Transfer Learning in FastEstimator\n",
    "\n",
    "Transfer learning is very frequently used in modern deep learning applications as it can greatly improve the performance and reduce training time.  In this tutorial, we will show you how train from existing weights.\n",
    "\n",
    "Long story short, user only needs to pass the model path in `fe.build` for transfer learning. We will use a simple MNIST classification as example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.architecture import LeNet\n",
    "from fastestimator.op.tensorop import Minmax, ModelOp, SparseCategoricalCrossentropy\n",
    "from fastestimator.trace import Accuracy, ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "print(\"model will be saved to {}\".format(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained-model by training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#step 1. prepare data\n",
    "(x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.mnist.load_data()\n",
    "train_data = {\"x\": np.expand_dims(x_train, -1), \"y\": y_train}\n",
    "eval_data = {\"x\": np.expand_dims(x_eval, -1), \"y\": y_eval}\n",
    "data = {\"train\": train_data, \"eval\": eval_data}\n",
    "pipeline = fe.Pipeline(batch_size=32, data=data, ops=Minmax(inputs=\"x\", outputs=\"x\"))\n",
    "\n",
    "# step 2. prepare model\n",
    "model = fe.build(model_def=LeNet, model_name=\"lenet\", optimizer=\"adam\", loss_name=\"loss\")\n",
    "\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"),\n",
    "    SparseCategoricalCrossentropy(inputs=(\"y\", \"y_pred\"), outputs=\"loss\")\n",
    "])\n",
    "\n",
    "# step 3.prepare estimator\n",
    "traces = [\n",
    "    Accuracy(true_key=\"y\", pred_key=\"y_pred\", output_name='acc'),\n",
    "    ModelSaver(model_name=\"lenet\", save_dir=model_dir, save_best=True)\n",
    "]\n",
    "estimator = fe.Estimator(network=network,\n",
    "                         pipeline=pipeline,\n",
    "                         epochs=2,\n",
    "                         traces=traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on existing weights\n",
    "The previous experiment produced a trained model, now we are going to load the model and continue training for two more batch. Note that the model path is used directly in `fe.build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = os.path.join(model_dir, \"lenet_best_loss.h5\")\n",
    "print(\"the model file path is {}\".format(model_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = fe.Pipeline(batch_size=32, data=data, ops=Minmax(inputs=\"x\", outputs=\"x\"))\n",
    "\n",
    "model = fe.build(model_def=model_file_path, model_name=\"lenet\", optimizer=\"adam\", loss_name=\"loss\")\n",
    "\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"),\n",
    "    SparseCategoricalCrossentropy(inputs=(\"y\", \"y_pred\"), outputs=\"loss\")\n",
    "])\n",
    "\n",
    "estimator = fe.Estimator(network=network,\n",
    "                         pipeline=pipeline,\n",
    "                         epochs=1,\n",
    "                         steps_per_epoch=2,\n",
    "                         traces=Accuracy(true_key=\"y\", pred_key=\"y_pred\", output_name='acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we use a pretrained weight, with only 2 steps of training, the accuracy is already around 99%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
