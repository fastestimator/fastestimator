{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 2: Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will discuss the following topics:\n",
    "\n",
    "* [Iterating Through Pipeline](#ta02itp)\n",
    "    * [Basic Concept](#ta02bc)\n",
    "    * [Example](#ta02example)\n",
    "* [Dropping Last Batch](#ta02dlb)\n",
    "* [Padding Batch Data](#ta02pbd)\n",
    "* [Benchmark Pipeline Speed](#ta02bps)\n",
    "\n",
    "In the [beginner tutorial 4](../beginner/t04_pipeline.ipynb), we learned how to build data pipeline that handles data loading and preprocessing tasks efficiently. Now that you have understood some basic operations in the `Pipeline`, we will demonstrate some advanced concepts and how to leverage them to create efficient `Pipeline` in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02itp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Through Pipeline\n",
    "\n",
    "In many deep learning tasks, the parameter of preprocessing task is precomputed by looping through the dataset. For example, in `ImageNet` dataset, people usually use a precomputed global pixel average for each channel to normalize the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02bc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will see how to iterate through the pipeline in FastEstimator. First we will create sample NumpyDataset from the data dictionary and load it into `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastestimator.dataset.data import cifar10\n",
    "    \n",
    "# sample numpy array to later create datasets from them\n",
    "x_train, y_train = (np.random.sample((10, 2)), np.random.sample((10, 1)))\n",
    "train_data = {\"x\": x_train, \"y\": y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastestimator as fe\n",
    "from fastestimator.dataset.numpy_dataset import NumpyDataset\n",
    "\n",
    "# create NumpyDataset from the sample data\n",
    "dataset_fe = NumpyDataset(train_data)\n",
    "\n",
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the loader object for the `Pipeline`, then iterate loader with a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0.7191, 0.1700],\n",
      "        [0.1704, 0.3014],\n",
      "        [0.5974, 0.5004]], dtype=torch.float64), 'y': tensor([[0.5230],\n",
      "        [0.6890],\n",
      "        [0.9531]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.8949, 0.5802],\n",
      "        [0.7846, 0.9987],\n",
      "        [0.7752, 0.2345]], dtype=torch.float64), 'y': tensor([[0.4932],\n",
      "        [0.6442],\n",
      "        [0.9859]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.2825, 0.3795],\n",
      "        [0.3616, 0.9058],\n",
      "        [0.9917, 0.2027]], dtype=torch.float64), 'y': tensor([[0.8371],\n",
      "        [0.7936],\n",
      "        [0.3906]], dtype=torch.float64)}\n",
      "{'x': tensor([[0.4236, 0.3067]], dtype=torch.float64), 'y': tensor([[0.2536]], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "loader_fe = pipeline_fe.get_loader(mode=\"train\")\n",
    "\n",
    "for batch in loader_fe:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02example'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have CIFAR-10 dataset and we want to find global average pixel value over three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.data import cifar10\n",
    "\n",
    "cifar_train, _ = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the `batch_size` 64 and load the data into `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cifar = fe.Pipeline(train_data=cifar_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will iterate through batch data and compute the mean pixel values for all three channels of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_fe = pipeline_cifar.get_loader(mode=\"train\", shuffle=False)\n",
    "mean_arr = np.zeros((3))\n",
    "for i, batch in enumerate(loader_fe):\n",
    "    mean_arr = mean_arr + np.mean(batch[\"x\"].numpy(), axis=(0, 1, 2))\n",
    "mean_arr = mean_arr / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pixel value over the channels are:  [125.32287898 122.96682199 113.8856495 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean pixel value over the channels are: \", mean_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02dlb'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Last Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `total number of data` is not dividable by `batch_size`, by default, the last batch will have less data than other batches.  To drop the last batch we can set `drop_last` to `True`. Therefore, if the last batch is incomplete it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02pbd'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Batch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be scenario where the input tensors have different dimensions within a batch. For example, in Natural language processing, we have input strings with different lengths. For that we need to pad the data to the maximum length within the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To further illustrate in code, we will take numpy array that contains different shapes of array elements and load it into the `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numpy arrays with different shapes\n",
    "elem1 = np.array([4, 5])\n",
    "elem2 = np.array([1, 2, 6])\n",
    "elem3 = np.array([3])\n",
    "\n",
    "# create train dataset\n",
    "x_train = np.array([elem1, elem2, elem3])\n",
    "train_data = {\"x\": x_train}\n",
    "dataset_fe = NumpyDataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set any `pad_value` that we want to append at the end of the tensor data. `pad_value` can be either `int` or `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fe = fe.Pipeline(train_data=dataset_fe, batch_size=3, pad_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the batch data after padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[4, 5, 0],\n",
      "        [1, 2, 6],\n",
      "        [3, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for elem in iter(pipeline_fe.get_loader(mode='train', shuffle=False)):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ta02bps'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Pipeline Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often the case that the bottleneck of deep learning training is data pipeline, as a result, GPU is underutilized. A speed diagnostic tool of `Pipeline` can help users checking the speed of pipeline and diagnose training speed problems.  The way to benchmark pipeline speed in FastEstimator is very simple: simply call `Pipeline.benchmark`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we will create `Pipeline` for the CIFAR-10 dataset with list of numpy operators that expand dimensions, apply `minmax` and finally rotate the input images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.numpyop.univariate import Minmax, ExpandDims\n",
    "from fastestimator.op.numpyop.multivariate import Rotate\n",
    "\n",
    "pipeline = fe.Pipeline(train_data=cifar_train,\n",
    "                       ops=[ExpandDims(inputs=\"x\", outputs=\"x\"),\n",
    "                            Minmax(inputs=\"x\", outputs=\"x_out\"),\n",
    "                            Rotate(image_in=\"x_out\", image_out=\"x_out\", limit=180)],\n",
    "                      batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark the processing speed in the training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator: Step: 100, Epoch: 1, Steps/sec: 341.9135233103771\n",
      "FastEstimator: Step: 200, Epoch: 1, Steps/sec: 563.0254899674627\n",
      "FastEstimator: Step: 300, Epoch: 1, Steps/sec: 671.5856149290763\n",
      "FastEstimator: Step: 400, Epoch: 1, Steps/sec: 856.025916954988\n",
      "FastEstimator: Step: 500, Epoch: 1, Steps/sec: 835.0631736638796\n",
      "FastEstimator: Step: 600, Epoch: 1, Steps/sec: 780.2817676962413\n",
      "FastEstimator: Step: 700, Epoch: 1, Steps/sec: 656.1022093672684\n"
     ]
    }
   ],
   "source": [
    "pipeline_cifar.benchmark(mode=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
