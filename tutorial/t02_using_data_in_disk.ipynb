{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Dealing with large datasets with FastEstimator\n",
    "_____\n",
    "\n",
    "In Tutorial 1, we introduced our 3 main APIs and general workflow of a deep learning task using FastEstimator:  `Pipeline` -> `Network` -> `Estimator`. Then we used in-memory data for training.  \n",
    "*__But what if the dataset size was too big to fit in memory? Imagine data is the size of ImageNet?__*\n",
    "\n",
    "The short answer is: __the user will use one more API to use in disk data for training: `RecordWriter`__, such that the overall workflow becomes:   \n",
    "`RecordWriter` -> `Pipeline` -> `Network` -> `Estimator`. In this tutorial, we are going to show you how to do in-disk data training in FastEstimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start:\n",
    "\n",
    "Two things are required regarding in-disk data : \n",
    "* Data files, obviously :)\n",
    "* A csv file that describes the data (prepare two csv files if you have a separate validation set)\n",
    "\n",
    "In the csv file, the rows of csv represent different examples and columns represent different features within example. For example, for a classification task, a csv may look like this:\n",
    "\n",
    "| image  | label  |\n",
    "|---|---|\n",
    "|/data/image1.png   | 0  |\n",
    "|/data/image2.png   |  1 |\n",
    "|/data/image3.png | 0  |\n",
    "|... | .  |\n",
    "\n",
    "The csv of a multi-mask segmentation task may look like this:\n",
    "\n",
    "| img  | msk1  | msk2  |\n",
    "|---|---|---|\n",
    "|/data/image1.png   | /maska/mask1.png  |/maskb/mask1.png|\n",
    "|/data/image2.png   |  /maska/mask2.png |/maskb/mask2.png|\n",
    "|/data/image3.png | /maska/mask3.png  |/maskb/mask3.png|\n",
    "|... | ...  |...|\n",
    "\n",
    "\n",
    "Please keep in mind that, there is no restriction on the data folder structures, number of features or name of features.  \n",
    "\n",
    "Now, let's generate some in-disk data for this tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Get the paths to the csv files\n",
    "\n",
    "For this example, we will use the function `load_data` from MNIST dataset to download the dataset and get the paths to the above-mentioned csv files for training, evaluation and to the data directory. \n",
    "You just have to use the paths for your specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training csv path is /tmp/.fe/Mnist/train.csv\n",
      "evaluation csv path is /tmp/.fe/Mnist/eval.csv\n",
      "mnist image path is /tmp/.fe/Mnist\n"
     ]
    }
   ],
   "source": [
    "from fastestimator.dataset.mnist import load_data\n",
    "\n",
    "train_csv, eval_csv, folder_path = load_data()\n",
    "print(\"training csv path is {}\".format(train_csv))\n",
    "print(\"evaluation csv path is {}\".format(eval_csv))\n",
    "print(\"mnist image path is {}\".format(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the csv file and image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image/train_0.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image/train_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image/train_2.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image/train_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image/train_4.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x  y\n",
       "0  image/train_0.png  5\n",
       "1  image/train_1.png  0\n",
       "2  image/train_2.png  4\n",
       "3  image/train_3.png  1\n",
       "4  image/train_4.png  9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth of image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "img = plt.imread(os.path.join(folder_path, df_train[\"x\"][1]))\n",
    "plt.imshow(img)\n",
    "print(\"ground truth of image is {}\".format(df_train[\"y\"][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: RecordWriter\n",
    "\n",
    "\n",
    "In FastEstimator, we convert user's in-disk data to TFRecord for the best training speed. The RecordWriter API takes care of it. \n",
    "\n",
    "You will have to specify : \n",
    "\n",
    "- `save_dir` : the path to write the record.    \n",
    "   \n",
    "   \n",
    "- `train_data` : can either be a csv path or a dictionary like the one used in tutorial 1.  \n",
    " \n",
    " \n",
    "- `validation_data` (optional) : it can take all input formats of `train_data`. In addition, `validation_data` can also take a floating point number between 0 to 1 which indicates the validation split ratio, then validation data will be randomly sampled from training data.  \n",
    " \n",
    " \n",
    "- `ops`: before converting data to TFRecord, users can apply a series of propcoessing tasks to the data in `ops` argument, we will talk about them in detail in tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.util import RecordWriter\n",
    "from fastestimator.op.numpyop import ImageReader\n",
    "import fastestimator as fe\n",
    "import tempfile\n",
    "\n",
    "# We simply create a RecordWriter will all required arguments. \n",
    "writer = RecordWriter(save_dir=os.path.join(folder_path, \"FEdata\"),\n",
    "                         train_data=train_csv,\n",
    "                         validation_data=eval_csv,\n",
    "                         ops=ImageReader(inputs=\"x\", parent_path=folder_path, outputs=\"x\", grey_scale=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pipeline -> Network -> Estimator (see tutorial 1 for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop import Minmax\n",
    "from fastestimator.architecture import LeNet\n",
    "from fastestimator.op.tensorop.model import ModelOp\n",
    "from fastestimator.op.tensorop.loss import SparseCategoricalCrossentropy\n",
    "\n",
    "# Pipeline creation\n",
    "pipeline = fe.Pipeline(batch_size=32, data=writer, ops=Minmax(inputs=\"x\", outputs=\"x\"))\n",
    "\n",
    "# Model and network definition\n",
    "model = fe.build(model_def=LeNet, model_name=\"lenet\", optimizer=\"adam\", loss_name=\"loss\")\n",
    "network = fe.Network(ops=[ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"), \n",
    "                          SparseCategoricalCrossentropy(y_pred=\"y_pred\", y_true=\"y\", outputs=\"loss\")])\n",
    "\n",
    "# Estimator definition\n",
    "estimator = fe.Estimator(network=network, pipeline=pipeline, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator: Saving tfrecord to /tmp/.fe/Mnist/FEdata\n",
      "FastEstimator: Converting Train TFRecords 0.0%, Speed: 0.00 record/sec\n",
      "FastEstimator: Converting Train TFRecords 5.0%, Speed: 25311.16 record/sec\n",
      "FastEstimator: Converting Train TFRecords 10.0%, Speed: 16474.48 record/sec\n",
      "FastEstimator: Converting Train TFRecords 15.0%, Speed: 12341.98 record/sec\n",
      "FastEstimator: Converting Train TFRecords 20.0%, Speed: 11620.45 record/sec\n",
      "FastEstimator: Converting Train TFRecords 25.0%, Speed: 11131.52 record/sec\n",
      "FastEstimator: Converting Train TFRecords 30.0%, Speed: 10988.09 record/sec\n",
      "FastEstimator: Converting Train TFRecords 35.0%, Speed: 10596.24 record/sec\n",
      "FastEstimator: Converting Train TFRecords 40.0%, Speed: 10305.17 record/sec\n",
      "FastEstimator: Converting Train TFRecords 45.0%, Speed: 10228.76 record/sec\n",
      "FastEstimator: Converting Train TFRecords 50.0%, Speed: 10132.39 record/sec\n",
      "FastEstimator: Converting Train TFRecords 55.0%, Speed: 10084.15 record/sec\n",
      "FastEstimator: Converting Train TFRecords 60.0%, Speed: 10059.63 record/sec\n",
      "FastEstimator: Converting Train TFRecords 65.0%, Speed: 10015.38 record/sec\n",
      "FastEstimator: Converting Train TFRecords 70.0%, Speed: 9937.32 record/sec\n",
      "FastEstimator: Converting Train TFRecords 75.0%, Speed: 9863.26 record/sec\n",
      "FastEstimator: Converting Train TFRecords 80.0%, Speed: 9807.95 record/sec\n",
      "FastEstimator: Converting Train TFRecords 85.0%, Speed: 9787.11 record/sec\n",
      "FastEstimator: Converting Train TFRecords 90.0%, Speed: 9682.32 record/sec\n",
      "FastEstimator: Converting Train TFRecords 95.0%, Speed: 9687.31 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 0.0%, Speed: 0.00 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 5.0%, Speed: 71333.40 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 9.9%, Speed: 33643.90 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 14.9%, Speed: 41380.53 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 19.8%, Speed: 30654.80 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 24.8%, Speed: 28463.06 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 29.8%, Speed: 27949.82 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 34.7%, Speed: 21332.26 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 39.7%, Speed: 17595.54 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 44.6%, Speed: 19030.31 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 49.6%, Speed: 16616.11 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 54.6%, Speed: 16706.31 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 59.5%, Speed: 14221.30 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 64.5%, Speed: 13732.77 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 69.4%, Speed: 13604.46 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 74.4%, Speed: 12936.53 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 79.4%, Speed: 12607.93 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 84.3%, Speed: 11888.54 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 89.3%, Speed: 12352.50 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 94.2%, Speed: 11802.17 record/sec\n",
      "FastEstimator: Converting Eval TFRecords 99.2%, Speed: 12120.14 record/sec\n",
      "FastEstimator: Reading non-empty directory: /tmp/.fe/Mnist/FEdata\n",
      "FastEstimator: Found 60000 examples for train in /tmp/.fe/Mnist/FEdata/train_summary0.json\n",
      "FastEstimator: Found 10000 examples for eval in /tmp/.fe/Mnist/FEdata/eval_summary0.json\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "FastEstimator-Start: step: 0; total_train_steps: 3750; lenet_lr: 0.001; \n",
      "FastEstimator-Train: step: 0; loss: 2.316646; \n",
      "FastEstimator-Train: step: 100; loss: 0.2023166; examples/sec: 1544.1; progress: 2.7%; \n",
      "FastEstimator-Train: step: 200; loss: 0.4131472; examples/sec: 1548.3; progress: 5.3%; \n",
      "FastEstimator-Train: step: 300; loss: 0.1216927; examples/sec: 1575.2; progress: 8.0%; \n",
      "FastEstimator-Train: step: 400; loss: 0.0763787; examples/sec: 1560.1; progress: 10.7%; \n",
      "FastEstimator-Train: step: 500; loss: 0.5539406; examples/sec: 1572.2; progress: 13.3%; \n",
      "FastEstimator-Train: step: 600; loss: 0.1830472; examples/sec: 1545.4; progress: 16.0%; \n",
      "FastEstimator-Train: step: 700; loss: 0.0571711; examples/sec: 1548.8; progress: 18.7%; \n",
      "FastEstimator-Train: step: 800; loss: 0.0670647; examples/sec: 1539.8; progress: 21.3%; \n",
      "FastEstimator-Train: step: 900; loss: 0.0689847; examples/sec: 1543.9; progress: 24.0%; \n",
      "FastEstimator-Train: step: 1000; loss: 0.2534505; examples/sec: 1534.3; progress: 26.7%; \n",
      "FastEstimator-Train: step: 1100; loss: 0.1595627; examples/sec: 1543.9; progress: 29.3%; \n",
      "FastEstimator-Train: step: 1200; loss: 0.1693894; examples/sec: 1535.8; progress: 32.0%; \n",
      "FastEstimator-Train: step: 1300; loss: 0.0614095; examples/sec: 1545.7; progress: 34.7%; \n",
      "FastEstimator-Train: step: 1400; loss: 0.02138; examples/sec: 1525.9; progress: 37.3%; \n",
      "FastEstimator-Train: step: 1500; loss: 0.0439597; examples/sec: 1531.7; progress: 40.0%; \n",
      "FastEstimator-Train: step: 1600; loss: 0.066583; examples/sec: 1523.1; progress: 42.7%; \n",
      "FastEstimator-Train: step: 1700; loss: 0.0377765; examples/sec: 1502.6; progress: 45.3%; \n",
      "FastEstimator-Train: step: 1800; loss: 0.044106; examples/sec: 1497.4; progress: 48.0%; \n",
      "FastEstimator-Eval: step: 1875; epoch: 0; loss: 0.0484788; min_loss: 0.048478775; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 1900; loss: 0.0396217; examples/sec: 752.4; progress: 50.7%; \n",
      "FastEstimator-Train: step: 2000; loss: 0.0075153; examples/sec: 1544.8; progress: 53.3%; \n",
      "FastEstimator-Train: step: 2100; loss: 0.0014823; examples/sec: 1522.4; progress: 56.0%; \n",
      "FastEstimator-Train: step: 2200; loss: 0.0135821; examples/sec: 1532.0; progress: 58.7%; \n",
      "FastEstimator-Train: step: 2300; loss: 0.0017681; examples/sec: 1531.1; progress: 61.3%; \n",
      "FastEstimator-Train: step: 2400; loss: 0.025974; examples/sec: 1529.5; progress: 64.0%; \n",
      "FastEstimator-Train: step: 2500; loss: 0.1640374; examples/sec: 1541.8; progress: 66.7%; \n",
      "FastEstimator-Train: step: 2600; loss: 0.0118217; examples/sec: 1555.9; progress: 69.3%; \n",
      "FastEstimator-Train: step: 2700; loss: 0.0811621; examples/sec: 1575.7; progress: 72.0%; \n",
      "FastEstimator-Train: step: 2800; loss: 0.077312; examples/sec: 1566.0; progress: 74.7%; \n",
      "FastEstimator-Train: step: 2900; loss: 0.0056092; examples/sec: 1551.9; progress: 77.3%; \n",
      "FastEstimator-Train: step: 3000; loss: 0.004439; examples/sec: 1529.8; progress: 80.0%; \n",
      "FastEstimator-Train: step: 3100; loss: 0.1169912; examples/sec: 1536.4; progress: 82.7%; \n",
      "FastEstimator-Train: step: 3200; loss: 0.0165762; examples/sec: 1536.1; progress: 85.3%; \n",
      "FastEstimator-Train: step: 3300; loss: 0.0012112; examples/sec: 1549.6; progress: 88.0%; \n",
      "FastEstimator-Train: step: 3400; loss: 0.0454505; examples/sec: 1536.0; progress: 90.7%; \n",
      "FastEstimator-Train: step: 3500; loss: 0.0044532; examples/sec: 1525.3; progress: 93.3%; \n",
      "FastEstimator-Train: step: 3600; loss: 0.0086824; examples/sec: 1523.1; progress: 96.0%; \n",
      "FastEstimator-Train: step: 3700; loss: 0.0135707; examples/sec: 1490.3; progress: 98.7%; \n",
      "FastEstimator-Eval: step: 3750; epoch: 1; loss: 0.0374213; min_loss: 0.03742133; since_best_loss: 0; \n",
      "FastEstimator-Finish: step: 3750; total_time: 88.41 sec; lenet_lr: 0.001; \n"
     ]
    }
   ],
   "source": [
    "# Launch the training!\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Key take-aways:\n",
    "\n",
    "As mentioned in tutorial 1, the preprocessing in the `RecordWriter` is a place for \"once-for-all\" type preprocessing. If a preprocessing function only needs to be done once (e,g, Resize and Rescale), then it is recommended to put them in `RecordWriter`. By doing this you can reduce the amount of computation needed during training and thereby train faster.\n",
    "\n",
    ">Now, let's summarize the **conceptual workflow** in FastEstimator for any deep learning task:\n",
    ">0. _[Optional]_ Do I have in-disk data or want to apply some preprocessing once and for all? _-> Express this in `RecordWriter`_\n",
    ">1. How do I want my data to be processed during the training? _-> Express this in `Pipeline`_\n",
    ">2. How do I want my network architecture and loss to be defined? what are the connections between networks if there are multiple of them? _-> Express this in `Network`_\n",
    ">3. How long do I train the model? what do I need during training loop? _-> Express this in `Estimator`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
