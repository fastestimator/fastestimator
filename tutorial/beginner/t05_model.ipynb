{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Model\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will cover:\n",
    "\n",
    "* [Instantiating and Compiling a Model](#t05compile)\n",
    "* [The Model Function](#t05model)\n",
    "    * [Custom Models](#t05custom)\n",
    "    * [FastEstimator Models](#t05fe)\n",
    "    * [Pre-Trained Models](#t05trained)\n",
    "* [The Optimizer Function](#t05optimizer)\n",
    "* [Loading Model Weights](#t05weights)\n",
    "* [Specifying a Model Name](#t05name)\n",
    "* [Related Apphub Examples](#t05apphub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05compile'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating and Compiling a model\n",
    "\n",
    "We need to specify two things to instantiate and compile a model:\n",
    "* model_fn\n",
    "* optimizer_fn\n",
    "\n",
    "Model definitions can be implemented in Tensorflow or Pytorch and instantiated by calling **`fe.build`** which constructs a model instance and associates it with the specified optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function\n",
    "\n",
    "`model_fn` should be a function/lambda function which returns either a `tf.keras.Model` or `torch.nn.Module`. FastEstimator provides several ways to specify the model architecture:\n",
    "\n",
    "* Custom model architecture\n",
    "* Importing a pre-built model architecture from FastEstimator\n",
    "* Importing pre-trained models/architectures from PyTorch or TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05custom'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model architecture\n",
    "Let's create a custom model in TensorFlow and PyTorch for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preliminary imports\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Since we will be mixing TF and Torch in the tutorial, we need to stop TF from taking all of the GPU memory.\n",
    "# Normally you would pick either TF or Torch, so you don't need to worry about this.\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import fastestimator as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 17:35:58.413575: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 17:35:58.978109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 34777 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "def my_model_tf(input_shape=(30, ), num_classes=2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Dense(8, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model_tf = fe.build(model_fn=my_model_tf, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model_torch(nn.Module):\n",
    "    def __init__(self, num_inputs=30, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(num_inputs, 32), \n",
    "                                    nn.ReLU(inplace=True), \n",
    "                                    nn.Linear(32, 8), \n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Linear(8, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x_label = torch.softmax(x, dim=-1)\n",
    "        return x_label\n",
    "\n",
    "    \n",
    "model_torch = fe.build(model_fn=my_model_torch, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05fe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing model architecture from FastEstimator\n",
    "\n",
    "Below we import a PyTorch LeNet architecture from FastEstimator. See our [Architectures](../../fastestimator/architecture) folder for a full list of the architectures provided by FastEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.architecture.pytorch import LeNet\n",
    "# from fastestimator.architecture.tensorflow import LeNet  # One can also use a TensorFlow model\n",
    "\n",
    "model = fe.build(model_fn=LeNet, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05trained'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing pre-trained models/architectures from PyTorch or TensorFlow\n",
    "\n",
    "Below we show how to define a model function using a pre-trained resnet model provided by TensorFlow and PyTorch respectively. We load the pre-trained models using a lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained model from tf.keras.applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_tf = fe.build(model_fn=lambda: tf.keras.applications.ResNet50(weights='imagenet'), optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained model from torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50_torch = fe.build(model_fn=lambda: models.resnet50(pretrained=True), optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05optimizer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer function\n",
    "\n",
    "`optimizer_fn` can be a string or lambda function.\n",
    "\n",
    "### Optimizer from String\n",
    "Specifying a string for the `optimizer_fn` loads the optimizer with default parameters. The optimizer strings accepted by FastEstimator are as follows:\n",
    "- Adadelta: 'adadelta'\n",
    "- Adagrad: 'adagrad'\n",
    "- Adam: 'adam'\n",
    "- Adamax: 'adamax'\n",
    "- RMSprop: 'rmsprop'\n",
    "- SGD: 'sgd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer from Function\n",
    "\n",
    "To specify specific values for the optimizer learning rate or other parameters, we need to pass a lambda function to the `optimizer_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow \n",
    "model_tf = fe.build(model_fn=my_model_tf, optimizer_fn=lambda: tf.optimizers.Adam(1e-4))\n",
    "\n",
    "# PyTorch\n",
    "model_torch = fe.build(model_fn=my_model_torch, optimizer_fn=lambda x: torch.optim.Adam(params=x, lr=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a model function returns multiple models, a list of optimizers can be provided. See the **[pggan apphub](../../apphub/image_generation/pggan/pggan.ipynb)** for an example with multiple models and optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05weights'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model weights\n",
    "\n",
    "We often need to load the weights of a saved model. Model weights can be loaded by specifying the path of the saved weights using the `weights_path` parameter. Let's use the resnet models created earlier to showcase this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights\n",
    "Here, we create a temporary directory and use FastEstimator backend to save the weights of our previously created resnet50 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpfnjigvpx/resnet50_torch.pt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "# TensorFlow\n",
    "fe.backend.save_model(resnet50_tf, save_dir=model_dir, model_name= \"resnet50_tf\")\n",
    "\n",
    "# PyTorch\n",
    "fe.backend.save_model(resnet50_torch, save_dir=model_dir, model_name= \"resnet50_torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading weights for TensorFlow and PyTorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "resnet50_tf = fe.build(model_fn=lambda: tf.keras.applications.ResNet50(weights=None), \n",
    "                       optimizer_fn=\"adam\", \n",
    "                       weights_path=os.path.join(model_dir, \"resnet50_tf.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "resnet50_torch = fe.build(model_fn=lambda: models.resnet50(pretrained=False), \n",
    "                          optimizer_fn=\"adam\", \n",
    "                          weights_path=os.path.join(model_dir, \"resnet50_torch.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05name'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a Model Name\n",
    "\n",
    "The name of a model can be specified using the `model_name` parameter. The name of the model is helpful in distinguishing models when multiple are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  LeNet\n"
     ]
    }
   ],
   "source": [
    "model = fe.build(model_fn=LeNet, optimizer_fn=\"adam\", model_name=\"LeNet\")\n",
    "print(\"Model Name: \", model.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a model function returns multiple models, a list of model_names can be given. See the **[pggan apphub](../../apphub/image_generation/pggan/pggan.ipynb)** for an illustration with multiple models and model names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t05apphub'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apphub Examples\n",
    "You can find some practical examples of the concepts described here in the following FastEstimator Apphubs:\n",
    "\n",
    "* [PG-GAN](../../apphub/image_generation/pggan/pggan.ipynb)\n",
    "* [Uncertainty Weighted Loss](../../apphub/multi_task_learning/uncertainty_weighted_loss/uncertainty_loss.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
