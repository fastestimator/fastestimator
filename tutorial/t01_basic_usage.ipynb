{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Basic Usage of FastEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In FastEstimator, there are 3 APIs that you need to know:\n",
    "\n",
    "* Pipeline: takes care of loading data and preprocessing data, it usually happens on CPU.\n",
    "* Network: responsible for trainable & differentiable model. It usually happens on GPU.\n",
    "* Estimator: manages training loop.\n",
    "\n",
    "Any deep learning implementation will follow the `Pipeline` -> `Network` -> `Estimator` process as illustrated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pipeline\n",
    "\n",
    "For in-memory data, `Pipeline` accepts a nested dictionary like {\"train\": {\"x\": x_train, \"y\": y_train}, \"eval\": {\"x\": x_eval, \"y\": y_eval}}. If valdiation data is not available, then `eval` key is not needed. We will leave the explanation of `ops` argument to tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import fastestimator as fe\n",
    "from fastestimator.pipeline.processing import Minmax\n",
    "\n",
    "(x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1) #adding channel dimension for convolution later\n",
    "x_eval = np.expand_dims(x_eval, -1) #adding channel dimension for convolution later\n",
    "data = {\"train\": {\"x\": x_train, \"y\": y_train}, \"eval\": {\"x\": x_eval, \"y\": y_eval}}\n",
    "pipeline = fe.Pipeline(batch_size=32, data=data, ops=Minmax(inputs=\"x\", outputs=\"x\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Network\n",
    "\n",
    "For Network architecture, users can choose one of the following:\n",
    "* Define a custom network architecture using  `tf.keras.Model` `tf.keras.Sequential`.  \n",
    "* Use existing architecture provided by `tf.keras.applications` or `fe.architecture`. \n",
    "\n",
    "In this tutorial, we are going to import a pre-defined LeNet architecture in [fastestimator.architecture.lenet](https://github.com/fastestimator/fastestimator/blob/master/fastestimator/architecture/lenet.py).\n",
    "\n",
    "After defining the architecture, we can associate model definition with its own optimizer and expected loss name (default to be 'loss') to `FEModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.architecture import LeNet\n",
    "from fastestimator.network.model import FEModel\n",
    "from fastestimator.network.model import ModelOp\n",
    "from fastestimator.network.loss import SparseCategoricalCrossentropy\n",
    "\n",
    "model = FEModel(model_def=LeNet, model_name=\"lenet\", optimizer=\"adam\", loss_name=\"loss\")\n",
    "network = fe.Network(ops=[ModelOp(inputs=\"x\", model=model, outputs=\"y_pred\"), \n",
    "                          SparseCategoricalCrossentropy(y_pred=\"y_pred\", y_true=\"y\", outputs=\"loss\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Estimator\n",
    "\n",
    "`Estimator` takes both `pipeline` and `network` and combines them in training loop. Here's the basic usage of `Estimator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(network=network, pipeline=pipeline, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training\n",
    "\n",
    "Since the data is already loaded in memory, the training is happening without any disk reading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we finish\n",
    "\n",
    "In order to implement your own ideas in FastEstimator, users first need to conceptually walk through the streamline of data and separate our the following things:\n",
    "1. How do I want my data to be processed during the training, --> Express them in `Pipeline`\n",
    "2. How do I want my network architecture and loss to be defined, what are the connections between networks if there are multiple of them. --> Express them in `Network`\n",
    "3. How long do I train the model, what do I need during training loop --> Express them in `Estimator`\n",
    "\n",
    "It is important to note that the preprocessing defined in `Pipeline` will be executed repeatedly for each batch during the training loop. However, some preprocessing only need to happen once and for all (e,g, Resize, Rescale). For that, we are going to talk about it in the next tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
