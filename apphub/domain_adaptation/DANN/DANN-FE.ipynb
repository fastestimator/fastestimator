{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradRev in FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import fastestimator as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data to /root/fastestimator_data/USPS\n",
      "100% [......................................................]    1.83 / 1.83 MB\n",
      "Extracting /root/fastestimator_data/USPS/zip.train.gz\n",
      "Downloading test data to /root/fastestimator_data/USPS\n",
      "100% [........................................................]  0.44 / 0.44 MB\n",
      "Extracting /root/fastestimator_data/USPS/zip.test.gz\n",
      "Writing image data to /root/fastestimator_data/USPS/image\n",
      "Data summary is saved at /root/fastestimator_data/USPS/train.csv\n",
      "Data summary is saved at /root/fastestimator_data/USPS/eval.csv\n",
      "Writing image data to /root/fastestimator_data/MNIST/image\n",
      "Data summary is saved at /root/fastestimator_data/MNIST/train.csv\n",
      "Data summary is saved at /root/fastestimator_data/MNIST/eval.csv\n"
     ]
    }
   ],
   "source": [
    "from fastestimator.dataset import mnist, usps\n",
    "from fastestimator.op.numpyop import ImageReader\n",
    "from fastestimator import RecordWriter\n",
    "\n",
    "usps_train_csv, usps_eval_csv, usps_parent_dir = usps.load_data()\n",
    "mnist_train_csv, mnist_eval_csv, mnist_parent_dir = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(mnist_train_csv)\n",
    "df.columns = ['source_img', 'source_label']\n",
    "df.to_csv(mnist_train_csv, index=False)\n",
    "\n",
    "df = pd.read_csv(usps_train_csv)\n",
    "df.columns = ['target_img', 'target_label']\n",
    "df.to_csv(usps_train_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop import Resize, Minmax\n",
    "\n",
    "writer = RecordWriter(save_dir=os.path.join(os.path.dirname(mnist_parent_dir), 'dann', 'tfr'),\n",
    "                      train_data=(usps_train_csv, mnist_train_csv),\n",
    "                      ops=(\n",
    "                          [ImageReader(inputs=\"target_img\", outputs=\"target_img\", parent_path=usps_parent_dir, grey_scale=True)], # first tuple element\n",
    "                          [ImageReader(inputs=\"source_img\", outputs=\"source_img\", parent_path=mnist_parent_dir, grey_scale=True)])) # second tuple element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = fe.Pipeline(\n",
    "    batch_size=batch_size,\n",
    "    data=writer,\n",
    "    ops=[\n",
    "        Resize(inputs=\"target_img\", outputs=\"target_img\", size=(28, 28)),\n",
    "        Resize(inputs=\"source_img\", outputs=\"source_img\", size=(28, 28)),\n",
    "        Minmax(inputs=\"target_img\", outputs=\"target_img\"),\n",
    "        Minmax(inputs=\"source_img\", outputs=\"source_img\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Reversal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, l):\n",
    "    def custom_grad(dy):\n",
    "        return tf.math.negative(dy)*l, None    \n",
    "    return tf.identity(x), custom_grad\n",
    "\n",
    "\n",
    "class GradReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, l=1):\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        \n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.l)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'l': self.l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = tf.Variable(0.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "def build_feature_extractor(img_shape=(28, 28, 1)):\n",
    "    x0 = layers.Input(shape=img_shape)\n",
    "    x = layers.Conv2D(32, 5, activation=\"relu\", padding=\"same\")(x0)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(48, 5, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    feat_map = layers.Flatten()(x)\n",
    "    return Model(inputs=x0, outputs=feat_map)\n",
    "\n",
    "\n",
    "def build_label_predictor(feat_dim):\n",
    "    x0 = layers.Input(shape=(feat_dim,))\n",
    "    x = layers.Dense(100, activation=\"relu\")(x0)\n",
    "    x = layers.Dense(100, activation=\"relu\")(x)\n",
    "    return Model(inputs=x0, outputs=x)\n",
    "\n",
    "def build_domain_predictor(feat_dim):\n",
    "    x0 = layers.Input(shape=(feat_dim,))\n",
    "    x = GradReversalLayer(l=alpha)(x0)\n",
    "    x = layers.Dense(100, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(inputs=x0, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(28, 28, 1)\n",
    "feat_dim = 7 * 7 * 48\n",
    "\n",
    "feature_extractor = fe.build(\n",
    "    model_def=lambda: build_feature_extractor(img_shape),\n",
    "    model_name=\"feature_extractor\",\n",
    "    loss_name=\"fe_loss\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")\n",
    "\n",
    "label_predictor = fe.build(\n",
    "    model_def=lambda: build_label_predictor(feat_dim),\n",
    "    model_name=\"label_predictor\",\n",
    "    loss_name=\"fe_loss\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")\n",
    "\n",
    "domain_predictor = fe.build(\n",
    "    model_def=lambda: build_domain_predictor(feat_dim),\n",
    "    model_name=\"domain_predictor\",\n",
    "    loss_name=\"fe_loss\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop.loss import Loss, BinaryCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class FELoss(Loss):\n",
    "    def __init__(self, inputs, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)        \n",
    "        self.label_loss_obj = losses.SparseCategoricalCrossentropy(reduction=losses.Reduction.NONE)\n",
    "        self.domain_loss_obj = losses.BinaryCrossentropy(reduction=losses.Reduction.NONE)        \n",
    "        \n",
    "    def forward(self, data, state):\n",
    "        src_c_logit, src_c_label, src_d_logit, tgt_d_logit = data\n",
    "        c_loss = self.label_loss_obj(y_true=src_c_label, y_pred=src_c_logit)\n",
    "        src_d_loss = self.domain_loss_obj(y_true=tf.zeros_like(src_d_logit), y_pred=src_d_logit) \n",
    "        tgt_d_loss = self.domain_loss_obj(y_true=tf.ones_like(tgt_d_logit), y_pred=tgt_d_logit)\n",
    "        return c_loss + src_d_loss + tgt_d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop.model import ModelOp\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=\"source_img\", outputs=\"src_feat\", model=feature_extractor),\n",
    "    ModelOp(inputs=\"target_img\", outputs=\"tgt_feat\", model=feature_extractor),\n",
    "    ModelOp(inputs=\"src_feat\", outputs=\"src_c_logit\", model=label_predictor),\n",
    "    ModelOp(inputs=\"src_feat\", outputs=\"src_d_logit\", model=domain_predictor),\n",
    "    ModelOp(inputs=\"tgt_feat\", outputs=\"tgt_d_logit\", model=domain_predictor),\n",
    "    FELoss(inputs=(\"src_c_logit\",\"source_label\", \"src_d_logit\", \"tgt_d_logit\"), outputs=\"fe_loss\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.trace import Trace\n",
    "from tensorflow.python.keras import backend\n",
    "\n",
    "class GRLWeightController(Trace):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__(inputs=None, outputs=None, mode=\"train\")\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def on_begin(self, state):\n",
    "        self.total_steps = state['total_train_steps']\n",
    "        \n",
    "    def on_batch_begin(self, state):\n",
    "        p = state['train_step'] / self.total_steps\n",
    "        current_alpha = float(2.0 / (1.0 + np.exp(-10.0 * p)) - 1.0)\n",
    "        backend.set_value(self.alpha, current_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [GRLWeightController(alpha=alpha)]\n",
    "\n",
    "estimator = fe.Estimator(\n",
    "    pipeline= pipeline, \n",
    "    network=network,\n",
    "    traces = traces,\n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator: Saving tfrecord to /root/fastestimator_data/dann/tfr\n",
      "FastEstimator: Converting Train TFRecords 0.0%, Speed: 0.00 record/sec\n",
      "FastEstimator: Converting Train TFRecords 5.0%, Speed: 13031.75 record/sec\n",
      "FastEstimator: Converting Train TFRecords 10.0%, Speed: 13740.44 record/sec\n",
      "FastEstimator: Converting Train TFRecords 15.0%, Speed: 14161.23 record/sec\n",
      "FastEstimator: Converting Train TFRecords 20.0%, Speed: 13921.10 record/sec\n",
      "FastEstimator: Converting Train TFRecords 25.0%, Speed: 13652.25 record/sec\n",
      "FastEstimator: Converting Train TFRecords 30.0%, Speed: 13783.91 record/sec\n",
      "FastEstimator: Converting Train TFRecords 34.9%, Speed: 13552.76 record/sec\n",
      "FastEstimator: Converting Train TFRecords 39.9%, Speed: 13730.83 record/sec\n",
      "FastEstimator: Converting Train TFRecords 44.9%, Speed: 13861.83 record/sec\n",
      "FastEstimator: Converting Train TFRecords 49.9%, Speed: 13765.78 record/sec\n",
      "FastEstimator: Converting Train TFRecords 54.9%, Speed: 13877.44 record/sec\n",
      "FastEstimator: Converting Train TFRecords 59.9%, Speed: 13973.37 record/sec\n",
      "FastEstimator: Converting Train TFRecords 64.9%, Speed: 14057.48 record/sec\n",
      "FastEstimator: Converting Train TFRecords 69.9%, Speed: 14127.93 record/sec\n",
      "FastEstimator: Converting Train TFRecords 74.9%, Speed: 13915.09 record/sec\n",
      "FastEstimator: Converting Train TFRecords 79.9%, Speed: 13986.91 record/sec\n",
      "FastEstimator: Converting Train TFRecords 84.9%, Speed: 14052.85 record/sec\n",
      "FastEstimator: Converting Train TFRecords 89.9%, Speed: 14220.18 record/sec\n",
      "FastEstimator: Converting Train TFRecords 94.8%, Speed: 14462.22 record/sec\n",
      "FastEstimator: Converting Train TFRecords 99.8%, Speed: 14689.29 record/sec\n",
      "FastEstimator: Converting Train TFRecords 0.0%, Speed: 0.00 record/sec\n",
      "FastEstimator: Converting Train TFRecords 5.0%, Speed: 16284.86 record/sec\n",
      "FastEstimator: Converting Train TFRecords 10.0%, Speed: 15639.08 record/sec\n",
      "FastEstimator: Converting Train TFRecords 15.0%, Speed: 15603.50 record/sec\n",
      "FastEstimator: Converting Train TFRecords 20.0%, Speed: 15553.39 record/sec\n",
      "FastEstimator: Converting Train TFRecords 25.0%, Speed: 15526.51 record/sec\n",
      "FastEstimator: Converting Train TFRecords 30.0%, Speed: 15506.20 record/sec\n",
      "FastEstimator: Converting Train TFRecords 35.0%, Speed: 15448.31 record/sec\n",
      "FastEstimator: Converting Train TFRecords 40.0%, Speed: 15445.04 record/sec\n",
      "FastEstimator: Converting Train TFRecords 45.0%, Speed: 15391.28 record/sec\n",
      "FastEstimator: Converting Train TFRecords 50.0%, Speed: 15387.64 record/sec\n",
      "FastEstimator: Converting Train TFRecords 55.0%, Speed: 15365.11 record/sec\n",
      "FastEstimator: Converting Train TFRecords 60.0%, Speed: 15364.88 record/sec\n",
      "FastEstimator: Converting Train TFRecords 65.0%, Speed: 15367.54 record/sec\n",
      "FastEstimator: Converting Train TFRecords 70.0%, Speed: 15375.67 record/sec\n",
      "FastEstimator: Converting Train TFRecords 75.0%, Speed: 15369.91 record/sec\n",
      "FastEstimator: Converting Train TFRecords 80.0%, Speed: 15374.26 record/sec\n",
      "FastEstimator: Converting Train TFRecords 85.0%, Speed: 15364.89 record/sec\n",
      "FastEstimator: Converting Train TFRecords 90.0%, Speed: 15368.11 record/sec\n",
      "FastEstimator: Converting Train TFRecords 95.0%, Speed: 15370.08 record/sec\n",
      "FastEstimator: Reading non-empty directory: /root/fastestimator_data/dann/tfr\n",
      "FastEstimator: Found 60000 examples for train in /root/fastestimator_data/dann/tfr/train_summary1.json\n",
      "FastEstimator: Found 7291 examples for train in /root/fastestimator_data/dann/tfr/train_summary0.json\n",
      "FastEstimator-Warn: No ModelSaver Trace detected. Models will not be saved.\n",
      "FastEstimator-Start: step: 0; total_train_steps: 5600; feature_extractor_lr: 1e-04; label_predictor_lr: 1e-04; domain_predictor_lr: 1e-04; \n",
      "FastEstimator-Train: step: 0; fe_loss: 13.643104; \n",
      "FastEstimator-Train: step: 100; fe_loss: 5.6126466; examples/sec: 6234.8; progress: 1.8%; \n",
      "FastEstimator-Train: step: 200; fe_loss: 3.2992709; examples/sec: 5796.7; progress: 3.6%; \n",
      "FastEstimator-Train: step: 300; fe_loss: 2.7959664; examples/sec: 5786.8; progress: 5.4%; \n",
      "FastEstimator-Train: step: 400; fe_loss: 3.5268488; examples/sec: 5795.2; progress: 7.1%; \n",
      "FastEstimator-Train: step: 500; fe_loss: 1.3976841; examples/sec: 2980.9; progress: 8.9%; \n",
      "FastEstimator-Train: step: 600; fe_loss: 3.4456549; examples/sec: 5810.3; progress: 10.7%; \n",
      "FastEstimator-Train: step: 700; fe_loss: 3.4947128; examples/sec: 5690.1; progress: 12.5%; \n",
      "FastEstimator-Train: step: 800; fe_loss: 3.953169; examples/sec: 5745.8; progress: 14.3%; \n",
      "FastEstimator-Train: step: 900; fe_loss: 4.6453443; examples/sec: 6612.1; progress: 16.1%; \n",
      "FastEstimator-Train: step: 1000; fe_loss: 4.498727; examples/sec: 2763.1; progress: 17.9%; \n",
      "FastEstimator-Train: step: 1100; fe_loss: 10.696444; examples/sec: 5778.1; progress: 19.6%; \n",
      "FastEstimator-Train: step: 1200; fe_loss: 3.164488; examples/sec: 5757.2; progress: 21.4%; \n",
      "FastEstimator-Train: step: 1300; fe_loss: 2.8882742; examples/sec: 6564.8; progress: 23.2%; \n",
      "FastEstimator-Train: step: 1400; fe_loss: 1.3108735; examples/sec: 5769.7; progress: 25.0%; \n",
      "FastEstimator-Train: step: 1500; fe_loss: 1.6697924; examples/sec: 2773.6; progress: 26.8%; \n",
      "FastEstimator-Train: step: 1600; fe_loss: 1.92518; examples/sec: 5784.0; progress: 28.6%; \n",
      "FastEstimator-Train: step: 1700; fe_loss: 2.5181038; examples/sec: 6432.9; progress: 30.4%; \n",
      "FastEstimator-Train: step: 1800; fe_loss: 2.3539174; examples/sec: 5742.7; progress: 32.1%; \n",
      "FastEstimator-Train: step: 1900; fe_loss: 2.6390986; examples/sec: 2775.2; progress: 33.9%; \n",
      "FastEstimator-Train: step: 2000; fe_loss: 2.6652212; examples/sec: 5786.3; progress: 35.7%; \n",
      "FastEstimator-Train: step: 2100; fe_loss: 3.2160487; examples/sec: 6541.5; progress: 37.5%; \n",
      "FastEstimator-Train: step: 2200; fe_loss: 5.0180774; examples/sec: 5710.9; progress: 39.3%; \n",
      "FastEstimator-Train: step: 2300; fe_loss: 3.1376023; examples/sec: 5765.4; progress: 41.1%; \n",
      "FastEstimator-Train: step: 2400; fe_loss: 2.322722; examples/sec: 2763.3; progress: 42.9%; \n",
      "FastEstimator-Train: step: 2500; fe_loss: 0.9632458; examples/sec: 6513.4; progress: 44.6%; \n",
      "FastEstimator-Train: step: 2600; fe_loss: 2.0330248; examples/sec: 5697.3; progress: 46.4%; \n",
      "FastEstimator-Train: step: 2700; fe_loss: 3.044993; examples/sec: 5745.0; progress: 48.2%; \n",
      "FastEstimator-Train: step: 2800; fe_loss: 3.3243728; examples/sec: 5756.4; progress: 50.0%; \n",
      "FastEstimator-Train: step: 2900; fe_loss: 8.957695; examples/sec: 2929.6; progress: 51.8%; \n",
      "FastEstimator-Train: step: 3000; fe_loss: 7.166307; examples/sec: 5789.7; progress: 53.6%; \n",
      "FastEstimator-Train: step: 3100; fe_loss: 4.7085238; examples/sec: 5757.6; progress: 55.4%; \n",
      "FastEstimator-Train: step: 3200; fe_loss: 3.980194; examples/sec: 5678.9; progress: 57.1%; \n",
      "FastEstimator-Train: step: 3300; fe_loss: 2.4930258; examples/sec: 2909.0; progress: 58.9%; \n",
      "FastEstimator-Train: step: 3400; fe_loss: 3.6806; examples/sec: 5733.5; progress: 60.7%; \n",
      "FastEstimator-Train: step: 3500; fe_loss: 3.8413055; examples/sec: 5734.1; progress: 62.5%; \n",
      "FastEstimator-Train: step: 3600; fe_loss: 3.3262591; examples/sec: 5728.8; progress: 64.3%; \n",
      "FastEstimator-Train: step: 3700; fe_loss: 1.7546473; examples/sec: 6555.5; progress: 66.1%; \n",
      "FastEstimator-Train: step: 3800; fe_loss: 2.462954; examples/sec: 2774.1; progress: 67.9%; \n",
      "FastEstimator-Train: step: 3900; fe_loss: 2.0216775; examples/sec: 5750.5; progress: 69.6%; \n",
      "FastEstimator-Train: step: 4000; fe_loss: 2.8102617; examples/sec: 5738.8; progress: 71.4%; \n",
      "FastEstimator-Train: step: 4100; fe_loss: 6.0943666; examples/sec: 5694.3; progress: 73.2%; \n",
      "FastEstimator-Train: step: 4200; fe_loss: 2.2591882; examples/sec: 6556.2; progress: 75.0%; \n",
      "FastEstimator-Train: step: 4300; fe_loss: 4.6883326; examples/sec: 2664.9; progress: 76.8%; \n",
      "FastEstimator-Train: step: 4400; fe_loss: 4.1738677; examples/sec: 5725.3; progress: 78.6%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 4500; fe_loss: 2.004524; examples/sec: 5736.6; progress: 80.4%; \n",
      "FastEstimator-Train: step: 4600; fe_loss: 2.4861064; examples/sec: 6489.4; progress: 82.1%; \n",
      "FastEstimator-Train: step: 4700; fe_loss: 1.7448742; examples/sec: 2757.3; progress: 83.9%; \n",
      "FastEstimator-Train: step: 4800; fe_loss: 1.9282994; examples/sec: 5722.5; progress: 85.7%; \n",
      "FastEstimator-Train: step: 4900; fe_loss: 1.3160886; examples/sec: 5739.0; progress: 87.5%; \n",
      "FastEstimator-Train: step: 5000; fe_loss: 1.5141902; examples/sec: 6585.9; progress: 89.3%; \n",
      "FastEstimator-Train: step: 5100; fe_loss: 3.653502; examples/sec: 5676.4; progress: 91.1%; \n",
      "FastEstimator-Train: step: 5200; fe_loss: 2.950117; examples/sec: 2728.6; progress: 92.9%; \n",
      "FastEstimator-Train: step: 5300; fe_loss: 2.2227886; examples/sec: 5666.0; progress: 94.6%; \n",
      "FastEstimator-Train: step: 5400; fe_loss: 1.6200781; examples/sec: 6464.9; progress: 96.4%; \n",
      "FastEstimator-Train: step: 5500; fe_loss: 1.6394211; examples/sec: 5701.0; progress: 98.2%; \n",
      "FastEstimator-Finish: step: 5600; total_time: 149.52 sec; feature_extractor_lr: 1e-04; label_predictor_lr: 1e-04; domain_predictor_lr: 1e-04; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
