{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# One-Shot Learning using Siamese Network in FastEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITZuApL56Mny"
   },
   "source": [
    "This notebook demonstrates how to perform one-shot learning using Siamese Network in FastEstimator.\n",
    "\n",
    "In one-shot learning we classify based on only a single example of each class. This ability of being able to learn from very little data could be useful in many machine learning problems.\n",
    "The details of the method are present in [Siamese neural networks for one-shot image recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n",
    "We will use Omniglot dataset for training and evaluation. The Omniglot dataset consists of 50 different alphabets split into background(30 alphabets) and evaluation(20 alphabets) sets.Each alphabet has a number of characters and each character has 20 images each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import fastestimator as fe\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Step 1: Defining Input Pipeline\n",
    "\n",
    "First, we will download the omnglot dataset which contains 1623 different handwritten characters from 50 different alphabets via our dataset API.\n",
    "The images will be first downloaded from [here](https://github.com/brendenlake/omniglot/).\n",
    "Then images for training and evaluation will be extracted and the path to them will be provided as train_path and eval_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [],
   "source": [
    "from fastestimator.dataset.omniglot import load_data\n",
    "train_path, eval_path = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the images are downloaded, we will use data generators which will read the data into memory and create batches for training and validation.\n",
    "For training, batches of data are created with half of the batch consisting of image pair from the same character and other half consiting of image pair from different characters. The target label is 1 for image pair from the same character and 0 otherwise. The aim is to learn similarity between any given pair of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "steps_per_epoch = 500\n",
    "validation_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.omniglot import get_batch\n",
    "\n",
    "data = {\"train\": lambda: get_batch(train_path, batch_size=batch_size), \n",
    "        \"eval\": lambda: get_batch(eval_path, batch_size=batch_size, is_train=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom operator to augment portion of the input data as described in the [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf). Given these operators we can now define `Pipeline` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op import TensorOp\n",
    "from fastestimator.op.tensorop import Minmax, Augmentation2D, Probability\n",
    "\n",
    "pipeline = fe.Pipeline(\n",
    "    data=data,\n",
    "    batch_size=batch_size,\n",
    "    ops=[\n",
    "        Probability(\n",
    "            tensor_op=Augmentation2D(inputs=\"x_a\",\n",
    "                                     outputs=\"x_a\",\n",
    "                                     mode=\"train\",\n",
    "                                     rotation_range=10.0,\n",
    "                                     shear_range=-0.3 * 180 / np.pi,\n",
    "                                     zoom_range=[0.8, 1.2],\n",
    "                                     width_shift_range=0.05,\n",
    "                                     height_shift_range=0.05),\n",
    "            prob=0.89),\n",
    "        Probability(\n",
    "            tensor_op=Augmentation2D(inputs=\"x_b\",\n",
    "                                     outputs=\"x_b\",\n",
    "                                     mode=\"train\",\n",
    "                                     rotation_range=10.0,\n",
    "                                     shear_range=-0.3 * 180 / np.pi,\n",
    "                                     zoom_range=[0.8, 1.2],\n",
    "                                     width_shift_range=0.05,\n",
    "                                     height_shift_range=0.05),\n",
    "            prob=0.89),\n",
    "        Minmax(inputs=\"x_a\", outputs=\"x_a\"),\n",
    "        Minmax(inputs=\"x_b\", outputs=\"x_b\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize sample images from the ``pipeline`` using ``show_results`` method.\n",
    "``show_results`` returns a list of batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image pair from same character\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image pair from different characters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_batch = pipeline.show_results()\n",
    "similar_img_a = sample_batch[0][\"x_a\"][0]\n",
    "similar_img_b = sample_batch[0][\"x_b\"][0]\n",
    "\n",
    "dissimilar_img_a = sample_batch[0][\"x_a\"][batch_size-1]\n",
    "dissimilar_img_b = sample_batch[0][\"x_b\"][batch_size-1]\n",
    "\n",
    "print('Image pair from same character')\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.squeeze(similar_img_a))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(similar_img_b))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Image pair from different characters')\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.squeeze(dissimilar_img_a))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(dissimilar_img_b))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Defining Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGrL73uCd-_M"
   },
   "source": [
    "Siamese network has two convolutional arms which accept distinct inputs. However, the weights on both these convolutional arms are shared. Each convolutional arm works as a feature extractor which produces a feature vector. L1 component-wise distance between these vectors is computed which is used to classify whether the image pair belongs to same or different classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Model, layers, Sequential\n",
    "from tensorflow.python.keras.initializers import RandomNormal\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "    \n",
    "\n",
    "def siamese_network(input_shape=(105, 105, 1), classes=1):\n",
    "    left_input = layers.Input(shape=input_shape)\n",
    "    right_input = layers.Input(shape=input_shape)\n",
    "\n",
    "    #Creating the convnet which shares weights between the left and right legs of Siamese network\n",
    "    siamese_convnet = Sequential()\n",
    "\n",
    "    siamese_convnet.add(\n",
    "        layers.Conv2D(filters=64,\n",
    "                      kernel_size=10,\n",
    "                      strides=1,\n",
    "                      input_shape=input_shape,\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=RandomNormal(mean=0, stddev=0.01),\n",
    "                      kernel_regularizer=l2(1e-2),\n",
    "                      bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "\n",
    "    siamese_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    siamese_convnet.add(\n",
    "        layers.Conv2D(filters=128,\n",
    "                      kernel_size=7,\n",
    "                      strides=1,\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=RandomNormal(mean=0, stddev=0.01),\n",
    "                      kernel_regularizer=l2(1e-2),\n",
    "                      bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "\n",
    "    siamese_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    siamese_convnet.add(\n",
    "        layers.Conv2D(filters=128,\n",
    "                      kernel_size=4,\n",
    "                      strides=1,\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=RandomNormal(mean=0, stddev=0.01),\n",
    "                      kernel_regularizer=l2(1e-2),\n",
    "                      bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "\n",
    "    siamese_convnet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    siamese_convnet.add(\n",
    "        layers.Conv2D(filters=256,\n",
    "                      kernel_size=4,\n",
    "                      strides=1,\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=RandomNormal(mean=0, stddev=0.01),\n",
    "                      kernel_regularizer=l2(1e-2),\n",
    "                      bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "\n",
    "    siamese_convnet.add(layers.Flatten())\n",
    "\n",
    "    siamese_convnet.add(\n",
    "        layers.Dense(4096,\n",
    "                     activation='sigmoid',\n",
    "                     kernel_initializer=RandomNormal(mean=0, stddev=0.2),\n",
    "                     kernel_regularizer=l2(1e-4),\n",
    "                     bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "\n",
    "    encoded_left_input = siamese_convnet(left_input)\n",
    "    encoded_right_input = siamese_convnet(right_input)\n",
    "\n",
    "    l1_encoded = layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([encoded_left_input, encoded_right_input])\n",
    "\n",
    "    output = layers.Dense(classes,\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer=RandomNormal(mean=0, stddev=0.2),\n",
    "                          bias_initializer=RandomNormal(mean=0.5, stddev=0.01))(l1_encoded)\n",
    "\n",
    "    return Model(inputs=[left_input, right_input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare the `model` and define a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop import ModelOp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from fastestimator.op.tensorop import BinaryCrossentropy\n",
    "\n",
    "model = fe.build(model_def=siamese_network, \n",
    "                 model_name=\"siamese_net\", \n",
    "                 optimizer=Adam(learning_rate=1e-4), \n",
    "                 loss_name=\"loss\")\n",
    "\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=[\"x_a\", \"x_b\"], model=model, outputs=\"y_pred\"),\n",
    "    BinaryCrossentropy(inputs=(\"y\", \"y_pred\"), outputs=\"loss\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will also use the following traces:\n",
    "1. LRController with a constant decay schedule as described in the [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n",
    "2. ModelSaver for saving the model. For illustration purpose, we will save these models in temporary directory.\n",
    "3. EarlyStopping for stopping training if the monitored metric doesn't improve within specified number of epochs.\n",
    "4. Custom trace to calculate one shot classification accuracy as described in the [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n",
    "It's a 20-way within-alphabet classiﬁcation task in which an alphabet is ﬁrst chosen from among those reserved for the evaluation set. Then, nineteen other characters are taken uniformly at random from the alphabet. The first charcter's image is compared with another image of the same character and with images of the other nineteen characters. This is called a one-shot trial. The trial is considered a success if the network outputs highest similarity (probability) for the image pair belonging to same character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from fastestimator.trace import Trace, LRController, ModelSaver, EarlyStopping\n",
    "from fastestimator.schedule import LRSchedule\n",
    "from fastestimator.dataset.omniglot import one_shot_trial, load_eval_data\n",
    "\n",
    "\n",
    "class LRDecaySchedule(LRSchedule):\n",
    "    def __init__(self, decay_rate=0.99):\n",
    "        super().__init__(schedule_mode=\"epoch\")\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def schedule_fn(self, current_step_or_epoch, lr):\n",
    "        if current_step_or_epoch > 0:\n",
    "            lr = np.float32(lr * self.decay_rate)\n",
    "        return lr\n",
    "\n",
    "\n",
    "class OneShotAccuracy(Trace):\n",
    "    def __init__(self, model, img_list, N=20, trials_per_alphabet=40, mode=\"eval\", output_name=\"one_shot_accuracy\"):\n",
    "\n",
    "        super().__init__(outputs=output_name, mode=mode)\n",
    "        self.model = model\n",
    "        self.total = 0\n",
    "        self.correct = 0\n",
    "        self.output_name = output_name\n",
    "        self.img_list = img_list\n",
    "        self.N = N\n",
    "        self.trials_per_alphabet = trials_per_alphabet\n",
    "\n",
    "    def on_epoch_begin(self, state):\n",
    "        self.total = 0\n",
    "        self.correct = 0\n",
    "\n",
    "    def on_epoch_end(self, state):\n",
    "        for alphabet in range(len(self.img_list)):\n",
    "\n",
    "            for _ in range(self.trials_per_alphabet):\n",
    "                input_img = one_shot_trial(self.img_list[alphabet], self.N)\n",
    "                prediction_score = self.model(input_img).numpy()\n",
    "\n",
    "                if np.argmax(prediction_score) == 0 and prediction_score.std() > 0.01:\n",
    "                    self.correct += 1\n",
    "\n",
    "                self.total += 1\n",
    "\n",
    "        state[self.output_name] = self.correct / self.total\n",
    "\n",
    "# Learning Rate Schedule\n",
    "lr_scheduler = LRDecaySchedule(decay_rate=0.99)\n",
    "\n",
    "# Loading images for validation one-shot accuracy\n",
    "val_img_list = load_eval_data(path=eval_path, is_test=False)\n",
    "\n",
    "# Model directory\n",
    "model_dir=tempfile.mkdtemp()\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "traces = [\n",
    "    LRController(model_name=\"siamese_net\", lr_schedule=lr_scheduler),\n",
    "    OneShotAccuracy(model=model, img_list=val_img_list, output_name='one_shot_accuracy'),\n",
    "    ModelSaver(model_name=\"siamese_net\", save_dir=model_dir, save_best='one_shot_accuracy', save_best_mode='max'),\n",
    "    EarlyStopping(monitor=\"one_shot_accuracy\", patience=20, compare='max', mode=\"eval\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to define `Estimator` object and then call `fit` method to start the training.\n",
    "Just for the sake of demo purpose, we would only run 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(network=network, \n",
    "                         pipeline=pipeline, \n",
    "                         epochs=epochs, \n",
    "                         steps_per_epoch=steps_per_epoch,\n",
    "                         validation_steps=validation_steps,\n",
    "                         traces=traces)\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are infering results on the test dataset. Here, we choose a language and generate 5-way one shot trial for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "saved_model = load_model(os.path.join(model_dir, 'siamese_net_best_one_shot_accuracy.h5'), compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language selected from Test Dataset\n",
    "language = 'Manipuri'\n",
    "\n",
    "characters = os.listdir(os.path.join(eval_path, language))\n",
    "\n",
    "char_img_list = []\n",
    "for character in characters:\n",
    "    img_paths = glob(os.path.join(eval_path, language, character, \"*.png\"))\n",
    "    imgs = [np.expand_dims(cv2.imread(i, cv2.IMREAD_GRAYSCALE), -1) for i in img_paths]\n",
    "    char_img_list.append(imgs)\n",
    "\n",
    "#Generating one-shot trial set for 5-way one shot trial\n",
    "input_img = one_shot_trial(char_img_list, 5)\n",
    "prediction_score = saved_model.predict(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(np.squeeze(input_img[0][0]));\n",
    "plt.title('test image')\n",
    "plt.axis('off');\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.subplot(151)\n",
    "plt.imshow(np.squeeze(input_img[1][0]));\n",
    "plt.title('Similarity with test image: {:0.2f}%'.format(100*prediction_score[0][0]))\n",
    "plt.axis('off');\n",
    "\n",
    "plt.subplot(152)\n",
    "plt.imshow(np.squeeze(input_img[1][1]));\n",
    "plt.title('Similarity with test image: {:0.2f}%'.format(100*prediction_score[1][0]))\n",
    "plt.axis('off');\n",
    "\n",
    "plt.subplot(153)\n",
    "plt.imshow(np.squeeze(input_img[1][2]));\n",
    "plt.title('Similarity with test image: {:0.2f}%'.format(100*prediction_score[2][0]))\n",
    "plt.axis('off');\n",
    "\n",
    "plt.subplot(154)\n",
    "plt.imshow(np.squeeze(input_img[1][3]));\n",
    "plt.title('Similarity with test image: {:0.2f}%'.format(100*prediction_score[3][0]))\n",
    "plt.axis('off');\n",
    "\n",
    "plt.subplot(155)\n",
    "plt.imshow(np.squeeze(input_img[1][4]));\n",
    "plt.title('Similarity with test image: {:0.2f}%'.format(100*prediction_score[4][0]))\n",
    "plt.axis('off');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test image is predicted to be belonging to the class with the maximum similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
