{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Example with MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.op import TensorOp\n",
    "from fastestimator.op.tensorop import Loss, ModelOp\n",
    "from fastestimator.trace import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "steps_per_epoch = None\n",
    "saved_model_path = 'gen_epoch_45_step_10764.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create `Pipeline` with MNIST data. With the help of `Myrescale` op, each image is normalized to between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myrescale(TensorOp):\n",
    "    \"\"\"Scale image values from uint8 to float32 between -1 and 1.\"\"\"\n",
    "    def forward(self, data, state):\n",
    "        data = tf.cast(data, tf.float32)\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "data = {\"train\": {\"x\": np.expand_dims(x_train, -1)}}\n",
    "pipeline = fe.Pipeline(batch_size=batch_size, data=data, ops=Myrescale(inputs=\"x\", outputs=\"x\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create `tf.keras` models for generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100, )))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we group the `tf.keras` models with `tf.optimizers` into `FEModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_femodel = fe.build(model_def=make_generator_model,\n",
    "                    model_name=\"gen\",\n",
    "                    loss_name=\"gloss\",\n",
    "                    optimizer=tf.optimizers.Adam(1e-4))\n",
    "d_femodel = fe.build(model_def=make_discriminator_model,\n",
    "                    model_name=\"disc\",\n",
    "                    loss_name=\"dloss\",\n",
    "                    optimizer=tf.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FEModel` and `Loss` will be grouped into `Network`. Let's define the loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the generator and discriminator loss. `Loss` can have multiple inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLoss(Loss):\n",
    "    \"\"\"Compute generator loss.\"\"\"\n",
    "    def __init__(self, inputs, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                                                reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        return self.cross_entropy(tf.ones_like(data), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLoss(Loss):\n",
    "    \"\"\"Compute discriminator loss.\"\"\"\n",
    "    def __init__(self, inputs, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                                                reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        true, fake = data\n",
    "        real_loss = self.cross_entropy(tf.ones_like(true), true)\n",
    "        fake_loss = self.cross_entropy(tf.zeros_like(fake), fake)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loss functions are defined, we group `FEModel` and loss functions into `Network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=lambda: tf.random.normal([batch_size, 100]), model=g_femodel),\n",
    "    ModelOp(model=d_femodel, outputs=\"pred_fake\"),\n",
    "    ModelOp(inputs=\"x\", model=d_femodel, outputs=\"pred_true\"),\n",
    "    GLoss(inputs=(\"pred_fake\"), outputs=\"gloss\"),\n",
    "    DLoss(inputs=(\"pred_true\", \"pred_fake\"), outputs=\"dloss\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Trace` is similar to callbacks in `tf.keras`. Here we use `ModelSaver` to save the training models to `save_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [ModelSaver(model_name='gen', save_dir=save_dir, save_freq=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once everything is combined into `Estimator`, we can start traniing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = fe.Estimator(network=network, pipeline=pipeline, epochs=epochs, steps_per_epoch=steps_per_epoch, traces=traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 17:48:19.117184 140658123323136 deprecation.py:323] From /data/hsiming/virtualenv/tf2.0.0b_py36_hsiming/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Start: step: 0; gen_lr: 1e-04; disc_lr: 1e-04; \n",
      "FastEstimator-Train: step: 0; gloss: 0.69595134; dloss: 1.3530326; \n",
      "FastEstimator-Train: step: 100; gloss: 0.6908619; dloss: 1.0262341; examples/sec: 2572.28; \n",
      "FastEstimator-Train: step: 200; gloss: 0.84497017; dloss: 1.2118433; examples/sec: 2543.57; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_0_step_234.h5\n",
      "FastEstimator-Train: step: 300; gloss: 0.926353; dloss: 1.0300479; examples/sec: 2575.34; \n",
      "FastEstimator-Train: step: 400; gloss: 0.7339307; dloss: 1.419587; examples/sec: 2547.12; \n",
      "FastEstimator-Train: step: 500; gloss: 1.1053416; dloss: 0.86561346; examples/sec: 2546.57; \n",
      "FastEstimator-Train: step: 600; gloss: 1.7596653; dloss: 0.52021855; examples/sec: 2525.99; \n",
      "FastEstimator-Train: step: 700; gloss: 0.9018482; dloss: 1.1085627; examples/sec: 2524.2; \n",
      "FastEstimator-Train: step: 800; gloss: 0.70425224; dloss: 1.4143591; examples/sec: 2520.55; \n",
      "FastEstimator-Train: step: 900; gloss: 0.83074707; dloss: 1.2864329; examples/sec: 2518.58; \n",
      "FastEstimator-Train: step: 1000; gloss: 0.8636123; dloss: 1.3568431; examples/sec: 2515.48; \n",
      "FastEstimator-Train: step: 1100; gloss: 0.7479536; dloss: 1.5826471; examples/sec: 2512.93; \n",
      "FastEstimator-Train: step: 1200; gloss: 0.7905136; dloss: 1.5097691; examples/sec: 2508.08; \n",
      "FastEstimator-Train: step: 1300; gloss: 0.7463613; dloss: 1.3998778; examples/sec: 2506.92; \n",
      "FastEstimator-Train: step: 1400; gloss: 0.8919745; dloss: 1.1551933; examples/sec: 2502.64; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_5_step_1404.h5\n",
      "FastEstimator-Train: step: 1500; gloss: 0.99319625; dloss: 1.0736455; examples/sec: 2528.45; \n",
      "FastEstimator-Train: step: 1600; gloss: 0.7286755; dloss: 1.5559127; examples/sec: 2503.4; \n",
      "FastEstimator-Train: step: 1700; gloss: 0.9155165; dloss: 1.1608633; examples/sec: 2504.74; \n",
      "FastEstimator-Train: step: 1800; gloss: 0.7434776; dloss: 1.3083016; examples/sec: 2511.11; \n",
      "FastEstimator-Train: step: 1900; gloss: 0.8758374; dloss: 1.3348733; examples/sec: 2503.19; \n",
      "FastEstimator-Train: step: 2000; gloss: 0.8166124; dloss: 1.2299441; examples/sec: 2508.8; \n",
      "FastEstimator-Train: step: 2100; gloss: 0.7107069; dloss: 1.4950066; examples/sec: 2510.15; \n",
      "FastEstimator-Train: step: 2200; gloss: 0.9786562; dloss: 1.0765682; examples/sec: 2509.23; \n",
      "FastEstimator-Train: step: 2300; gloss: 0.90990275; dloss: 1.3727658; examples/sec: 2510.82; \n",
      "FastEstimator-Train: step: 2400; gloss: 1.091837; dloss: 0.9914036; examples/sec: 2507.73; \n",
      "FastEstimator-Train: step: 2500; gloss: 0.84776753; dloss: 1.4775909; examples/sec: 2512.6; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_10_step_2574.h5\n",
      "FastEstimator-Train: step: 2600; gloss: 0.9051596; dloss: 1.2369817; examples/sec: 2530.37; \n",
      "FastEstimator-Train: step: 2700; gloss: 1.0139004; dloss: 1.1593926; examples/sec: 2499.25; \n",
      "FastEstimator-Train: step: 2800; gloss: 0.88000095; dloss: 1.294114; examples/sec: 2501.75; \n",
      "FastEstimator-Train: step: 2900; gloss: 1.0820124; dloss: 1.2039725; examples/sec: 2505.4; \n",
      "FastEstimator-Train: step: 3000; gloss: 1.3538215; dloss: 0.8107094; examples/sec: 2512.37; \n",
      "FastEstimator-Train: step: 3100; gloss: 0.95700437; dloss: 1.234808; examples/sec: 2508.88; \n",
      "FastEstimator-Train: step: 3200; gloss: 1.1537837; dloss: 1.12163; examples/sec: 2513.07; \n",
      "FastEstimator-Train: step: 3300; gloss: 0.9400153; dloss: 1.2380682; examples/sec: 2508.47; \n",
      "FastEstimator-Train: step: 3400; gloss: 1.1326759; dloss: 0.9954937; examples/sec: 2512.64; \n",
      "FastEstimator-Train: step: 3500; gloss: 1.120005; dloss: 1.0653719; examples/sec: 2506.08; \n",
      "FastEstimator-Train: step: 3600; gloss: 1.0102966; dloss: 1.1714345; examples/sec: 2510.13; \n",
      "FastEstimator-Train: step: 3700; gloss: 0.9641124; dloss: 1.1828768; examples/sec: 2511.86; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_15_step_3744.h5\n",
      "FastEstimator-Train: step: 3800; gloss: 1.1241753; dloss: 1.1056703; examples/sec: 2537.43; \n",
      "FastEstimator-Train: step: 3900; gloss: 1.2800107; dloss: 0.87076414; examples/sec: 2513.6; \n",
      "FastEstimator-Train: step: 4000; gloss: 1.0173273; dloss: 1.2648131; examples/sec: 2515.4; \n",
      "FastEstimator-Train: step: 4100; gloss: 1.2626874; dloss: 0.96767735; examples/sec: 2512.22; \n",
      "FastEstimator-Train: step: 4200; gloss: 1.0998651; dloss: 1.3161542; examples/sec: 2514.09; \n",
      "FastEstimator-Train: step: 4300; gloss: 1.1622956; dloss: 1.0845126; examples/sec: 2510.16; \n",
      "FastEstimator-Train: step: 4400; gloss: 1.8857236; dloss: 0.61238563; examples/sec: 2514.08; \n",
      "FastEstimator-Train: step: 4500; gloss: 1.4766601; dloss: 0.91755694; examples/sec: 2509.08; \n",
      "FastEstimator-Train: step: 4600; gloss: 1.0801171; dloss: 1.2520044; examples/sec: 2512.96; \n",
      "FastEstimator-Train: step: 4700; gloss: 1.136924; dloss: 1.0787942; examples/sec: 2510.29; \n",
      "FastEstimator-Train: step: 4800; gloss: 1.1364374; dloss: 0.9225644; examples/sec: 2511.47; \n",
      "FastEstimator-Train: step: 4900; gloss: 0.98714125; dloss: 1.234557; examples/sec: 2509.48; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_20_step_4914.h5\n",
      "FastEstimator-Train: step: 5000; gloss: 1.2132232; dloss: 1.0075278; examples/sec: 2535.8; \n",
      "FastEstimator-Train: step: 5100; gloss: 1.2478071; dloss: 0.9712628; examples/sec: 2509.19; \n",
      "FastEstimator-Train: step: 5200; gloss: 1.0746053; dloss: 1.1861095; examples/sec: 2510.04; \n",
      "FastEstimator-Train: step: 5300; gloss: 1.156363; dloss: 1.0273391; examples/sec: 2511.7; \n",
      "FastEstimator-Train: step: 5400; gloss: 1.2215666; dloss: 1.0596297; examples/sec: 2509.72; \n",
      "FastEstimator-Train: step: 5500; gloss: 1.1053557; dloss: 1.1561103; examples/sec: 2511.24; \n",
      "FastEstimator-Train: step: 5600; gloss: 1.137301; dloss: 1.0941685; examples/sec: 2511.83; \n",
      "FastEstimator-Train: step: 5700; gloss: 1.6252682; dloss: 0.77302194; examples/sec: 2510.78; \n",
      "FastEstimator-Train: step: 5800; gloss: 1.1551921; dloss: 1.0950768; examples/sec: 2512.56; \n",
      "FastEstimator-Train: step: 5900; gloss: 0.8808057; dloss: 1.3883932; examples/sec: 2512.7; \n",
      "FastEstimator-Train: step: 6000; gloss: 1.4769766; dloss: 0.88300925; examples/sec: 2514.09; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_25_step_6084.h5\n",
      "FastEstimator-Train: step: 6100; gloss: 1.5844681; dloss: 0.97752; examples/sec: 2539.13; \n",
      "FastEstimator-Train: step: 6200; gloss: 1.4207733; dloss: 1.009416; examples/sec: 2514.43; \n",
      "FastEstimator-Train: step: 6300; gloss: 1.5112205; dloss: 0.89121306; examples/sec: 2507.89; \n",
      "FastEstimator-Train: step: 6400; gloss: 1.5947648; dloss: 0.84250724; examples/sec: 2511.99; \n",
      "FastEstimator-Train: step: 6500; gloss: 1.1048834; dloss: 1.1508973; examples/sec: 2507.87; \n",
      "FastEstimator-Train: step: 6600; gloss: 1.1830401; dloss: 1.1891085; examples/sec: 2493.49; \n",
      "FastEstimator-Train: step: 6700; gloss: 1.2354956; dloss: 1.0502173; examples/sec: 2526.42; \n",
      "FastEstimator-Train: step: 6800; gloss: 1.2081039; dloss: 0.98759186; examples/sec: 2510.29; \n",
      "FastEstimator-Train: step: 6900; gloss: 1.1010578; dloss: 1.1570222; examples/sec: 2512.99; \n",
      "FastEstimator-Train: step: 7000; gloss: 1.102396; dloss: 1.1259654; examples/sec: 2509.66; \n",
      "FastEstimator-Train: step: 7100; gloss: 1.0229583; dloss: 1.1374489; examples/sec: 2509.6; \n",
      "FastEstimator-Train: step: 7200; gloss: 1.0148576; dloss: 1.1703944; examples/sec: 2503.72; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_30_step_7254.h5\n",
      "FastEstimator-Train: step: 7300; gloss: 0.98689145; dloss: 1.3194159; examples/sec: 2527.63; \n",
      "FastEstimator-Train: step: 7400; gloss: 0.9941745; dloss: 1.2021219; examples/sec: 2507.91; \n",
      "FastEstimator-Train: step: 7500; gloss: 1.1889787; dloss: 1.2863231; examples/sec: 2505.05; \n",
      "FastEstimator-Train: step: 7600; gloss: 0.940554; dloss: 1.201722; examples/sec: 2507.25; \n",
      "FastEstimator-Train: step: 7700; gloss: 1.2296163; dloss: 1.069271; examples/sec: 2506.61; \n",
      "FastEstimator-Train: step: 7800; gloss: 1.1145477; dloss: 1.0264305; examples/sec: 2507.93; \n",
      "FastEstimator-Train: step: 7900; gloss: 0.8749032; dloss: 1.3487043; examples/sec: 2502.44; \n",
      "FastEstimator-Train: step: 8000; gloss: 1.1489267; dloss: 1.2460017; examples/sec: 2494.68; \n",
      "FastEstimator-Train: step: 8100; gloss: 1.0383592; dloss: 1.2838305; examples/sec: 2501.11; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 8200; gloss: 1.0881394; dloss: 1.1826886; examples/sec: 2504.92; \n",
      "FastEstimator-Train: step: 8300; gloss: 1.195807; dloss: 1.1842307; examples/sec: 2504.99; \n",
      "FastEstimator-Train: step: 8400; gloss: 1.2090687; dloss: 1.031111; examples/sec: 2506.24; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_35_step_8424.h5\n",
      "FastEstimator-Train: step: 8500; gloss: 1.1117153; dloss: 1.1760783; examples/sec: 2525.56; \n",
      "FastEstimator-Train: step: 8600; gloss: 1.0358796; dloss: 1.1525894; examples/sec: 2502.79; \n",
      "FastEstimator-Train: step: 8700; gloss: 1.080224; dloss: 1.2292671; examples/sec: 2501.15; \n",
      "FastEstimator-Train: step: 8800; gloss: 0.93098855; dloss: 1.3154166; examples/sec: 2504.21; \n",
      "FastEstimator-Train: step: 8900; gloss: 1.0154734; dloss: 1.29711; examples/sec: 2509.68; \n",
      "FastEstimator-Train: step: 9000; gloss: 1.1050225; dloss: 1.2516804; examples/sec: 2511.56; \n",
      "FastEstimator-Train: step: 9100; gloss: 0.97036177; dloss: 1.1775709; examples/sec: 2516.14; \n",
      "FastEstimator-Train: step: 9200; gloss: 0.9703679; dloss: 1.1825461; examples/sec: 2511.75; \n",
      "FastEstimator-Train: step: 9300; gloss: 0.97972953; dloss: 1.1862504; examples/sec: 2517.75; \n",
      "FastEstimator-Train: step: 9400; gloss: 1.0387019; dloss: 1.2318416; examples/sec: 2515.34; \n",
      "FastEstimator-Train: step: 9500; gloss: 0.99222374; dloss: 1.1574038; examples/sec: 2513.03; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_40_step_9594.h5\n",
      "FastEstimator-Train: step: 9600; gloss: 0.9064344; dloss: 1.4716201; examples/sec: 2539.71; \n",
      "FastEstimator-Train: step: 9700; gloss: 0.8087839; dloss: 1.3511995; examples/sec: 2510.16; \n",
      "FastEstimator-Train: step: 9800; gloss: 1.0436379; dloss: 1.3033727; examples/sec: 2514.61; \n",
      "FastEstimator-Train: step: 9900; gloss: 1.0533434; dloss: 1.1115111; examples/sec: 2509.67; \n",
      "FastEstimator-Train: step: 10000; gloss: 1.0845108; dloss: 0.9845184; examples/sec: 2515.79; \n",
      "FastEstimator-Train: step: 10100; gloss: 1.0451509; dloss: 1.1416662; examples/sec: 2515.34; \n",
      "FastEstimator-Train: step: 10200; gloss: 1.04123; dloss: 1.3000846; examples/sec: 2510.31; \n",
      "FastEstimator-Train: step: 10300; gloss: 1.0057669; dloss: 1.1370484; examples/sec: 2513.13; \n",
      "FastEstimator-Train: step: 10400; gloss: 0.9891538; dloss: 1.1220548; examples/sec: 2508.24; \n",
      "FastEstimator-Train: step: 10500; gloss: 0.9103876; dloss: 1.1989634; examples/sec: 2506.41; \n",
      "FastEstimator-Train: step: 10600; gloss: 0.8733444; dloss: 1.2306137; examples/sec: 2506.7; \n",
      "FastEstimator-Train: step: 10700; gloss: 0.8079326; dloss: 1.3260518; examples/sec: 2504.22; \n",
      "FastEstimator-ModelSaver: Saving model to /tmp/tmpzdhf6mjv/gen_epoch_45_step_10764.h5\n",
      "FastEstimator-Train: step: 10800; gloss: 0.9123037; dloss: 1.2398833; examples/sec: 2532.67; \n",
      "FastEstimator-Train: step: 10900; gloss: 0.8901875; dloss: 1.2088764; examples/sec: 2508.35; \n",
      "FastEstimator-Train: step: 11000; gloss: 0.91047853; dloss: 1.2530726; examples/sec: 2513.45; \n",
      "FastEstimator-Train: step: 11100; gloss: 0.9310628; dloss: 1.2619432; examples/sec: 2513.6; \n",
      "FastEstimator-Train: step: 11200; gloss: 1.0029485; dloss: 1.1431831; examples/sec: 2509.66; \n",
      "FastEstimator-Train: step: 11300; gloss: 1.0093205; dloss: 1.1072545; examples/sec: 2512.57; \n",
      "FastEstimator-Train: step: 11400; gloss: 1.095667; dloss: 1.0824221; examples/sec: 2508.67; \n",
      "FastEstimator-Train: step: 11500; gloss: 1.0731249; dloss: 1.1650423; examples/sec: 2513.0; \n",
      "FastEstimator-Train: step: 11600; gloss: 0.9874201; dloss: 1.2624488; examples/sec: 2511.64; \n",
      "FastEstimator-Finish: step: 11700; total_time: 1196.22 sec; gen_lr: 1e-04; disc_lr: 1e-04; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images from random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the trained generator to generate images of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 18:10:09.384269 140658123323136 hdf5_format.py:171] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(os.path.join(save_dir, saved_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = model.predict(np.random.normal(size=(16, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 4)\n",
    "axes = np.ravel(axes)\n",
    "for i in range(images.shape[0]):\n",
    "    axes[i].axis('off')\n",
    "    axes[i].imshow(np.squeeze(images[i, ...] * 127.5 + 127.5), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
