{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Reviews sentiments prediction using LSTM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "import fastestimator as fe\n",
    "from fastestimator.dataset.data import imdb_review\n",
    "from fastestimator.op.numpyop.univariate.reshape import Reshape\n",
    "from fastestimator.op.tensorop.loss import CrossEntropy\n",
    "from fastestimator.op.tensorop.model import ModelOp, UpdateOp\n",
    "from fastestimator.trace.io import BestModelSaver\n",
    "from fastestimator.trace.metric import Accuracy\n",
    "from fastestimator.backend import feed_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 500\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "max_steps_per_epoch = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building components</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Prepare training & evaluation data and define Pipeline</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the dataset from the tf.keras.datasets.imdb which contains movie reviews and sentiment scores. All the words have been replaced with the integers that specifies the popularity of the word in corpus. To ensure all the sequences are of same length we need to pad the input sequences before defining the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data = imdb_review.load_data(MAX_LEN, MAX_WORDS)\n",
    "pipeline = fe.Pipeline(train_data=train_data,\n",
    "                       eval_data=eval_data,\n",
    "                       batch_size=batch_size,\n",
    "                       ops=Reshape(1, inputs=\"y\", outputs=\"y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Create model and FastEstimator network</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to define the network architecture and after defining the architecture, users are expected to feed the architecture definition, its associated model name and optimizer to fe.build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewSentiment(nn.Module):\n",
    "    def __init__(self, embedding_size=64, hidden_units=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(MAX_WORDS, embedding_size)\n",
    "        self.conv1d = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.maxpool1d = nn.MaxPool1d(kernel_size=4)\n",
    "        self.lstm = nn.LSTM(input_size=125, hidden_size=hidden_units, num_layers=1)\n",
    "        self.fc1 = nn.Linear(in_features=hidden_units, out_features=250)\n",
    "        self.fc2 = nn.Linear(in_features=250, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute((0, 2, 1))\n",
    "        x = self.conv1d(x)\n",
    "        x = fn.relu(x)\n",
    "        x = self.maxpool1d(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        x = output[:, -1]  # sequence output of only last timestamp\n",
    "        x = fn.tanh(x)\n",
    "        x = self.fc1(x)\n",
    "        x = fn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = fn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is the object that define the whole logic of neural network, including models, loss functions, optimizers etc. A Network can have several different models and loss funcitons (like GAN). <b>fe.Network</b> takes series of operators and here we feed our model in the ModelOp with inputs and outputs. It should be noted that the y_pred is the key in the data dictionary which will store the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fe.build(model_fn=lambda: ReviewSentiment(), optimizer_fn=\"adam\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(model=model, inputs=\"x\", outputs=\"y_pred\"),\n",
    "    CrossEntropy(inputs=(\"y_pred\", \"y\"), outputs=\"loss\"),\n",
    "    UpdateOp(model=model, loss_name=\"loss\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Prepare estimator and configure the training loop</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Estimator</b> is the API that wrap up the Pipeline, Network and other training metadata together. Estimator basically has four arguments network, pipeline, epochs and traces. Network and Pipeline objects are passed here as an argument. Traces are similar to the callbacks of Keras. The trace object will be called on specific timing during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop, we want to measure the validation loss and save the model that has the minimum loss. BestModelSaver and Accuracy in the Trace class provide this convenient feature of storing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "traces = [Accuracy(true_key=\"y\", pred_key=\"y_pred\"), BestModelSaver(model=model, save_dir=model_dir)]\n",
    "estimator = fe.Estimator(network=network,\n",
    "                         pipeline=pipeline,\n",
    "                         epochs=epochs,\n",
    "                         traces=traces,\n",
    "                         max_steps_per_epoch=max_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator-Start: step: 1; model_lr: 0.001; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fe_env/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/ubuntu/anaconda3/envs/fe_env/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 1; loss: 0.6905144; \n",
      "FastEstimator-Train: step: 100; loss: 0.69094294; steps/sec: 46.99; \n",
      "FastEstimator-Train: step: 200; loss: 0.6621749; steps/sec: 48.85; \n",
      "FastEstimator-Train: step: 300; loss: 0.5835465; steps/sec: 54.12; \n",
      "FastEstimator-Train: step: 391; epoch: 1; epoch_time: 7.74 sec; \n",
      "Saved model to /tmp/tmp69qyfzvm/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 391; epoch: 1; loss: 0.5250161; min_loss: 0.5250161; since_best: 0; accuracy: 0.7377667446412374; \n",
      "FastEstimator-Train: step: 400; loss: 0.51533854; steps/sec: 55.54; \n",
      "FastEstimator-Train: step: 500; loss: 0.6381638; steps/sec: 60.01; \n",
      "FastEstimator-Train: step: 600; loss: 0.4390931; steps/sec: 58.14; \n",
      "FastEstimator-Train: step: 700; loss: 0.32808638; steps/sec: 59.57; \n",
      "FastEstimator-Train: step: 782; epoch: 2; epoch_time: 6.7 sec; \n",
      "Saved model to /tmp/tmp69qyfzvm/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 782; epoch: 2; loss: 0.41990075; min_loss: 0.41990075; since_best: 0; accuracy: 0.8072277653124552; \n",
      "FastEstimator-Train: step: 800; loss: 0.4495564; steps/sec: 56.01; \n",
      "FastEstimator-Train: step: 900; loss: 0.38001418; steps/sec: 60.14; \n",
      "FastEstimator-Train: step: 1000; loss: 0.28246647; steps/sec: 60.33; \n",
      "FastEstimator-Train: step: 1100; loss: 0.36126548; steps/sec: 60.51; \n",
      "FastEstimator-Train: step: 1173; epoch: 3; epoch_time: 6.63 sec; \n",
      "Saved model to /tmp/tmp69qyfzvm/model_best_loss.pt\n",
      "FastEstimator-Eval: step: 1173; epoch: 3; loss: 0.39232534; min_loss: 0.39232534; since_best: 0; accuracy: 0.8241752995655702; \n",
      "FastEstimator-Train: step: 1200; loss: 0.32620478; steps/sec: 55.57; \n",
      "FastEstimator-Train: step: 1300; loss: 0.33430642; steps/sec: 60.1; \n",
      "FastEstimator-Train: step: 1400; loss: 0.21134894; steps/sec: 62.23; \n",
      "FastEstimator-Train: step: 1500; loss: 0.34480703; steps/sec: 62.4; \n",
      "FastEstimator-Train: step: 1564; epoch: 4; epoch_time: 6.47 sec; \n",
      "FastEstimator-Eval: step: 1564; epoch: 4; loss: 0.3997118; min_loss: 0.39232534; since_best: 1; accuracy: 0.8274693273499785; \n",
      "FastEstimator-Train: step: 1600; loss: 0.14769143; steps/sec: 57.72; \n",
      "FastEstimator-Train: step: 1700; loss: 0.17477548; steps/sec: 60.4; \n",
      "FastEstimator-Train: step: 1800; loss: 0.34234992; steps/sec: 60.82; \n",
      "FastEstimator-Train: step: 1900; loss: 0.34789586; steps/sec: 61.12; \n",
      "FastEstimator-Train: step: 1955; epoch: 5; epoch_time: 6.55 sec; \n",
      "FastEstimator-Eval: step: 1955; epoch: 5; loss: 0.39978975; min_loss: 0.39232534; since_best: 2; accuracy: 0.8300950016708837; \n",
      "FastEstimator-Train: step: 2000; loss: 0.21192178; steps/sec: 56.29; \n",
      "FastEstimator-Train: step: 2100; loss: 0.24565384; steps/sec: 60.85; \n",
      "FastEstimator-Train: step: 2200; loss: 0.21373041; steps/sec: 60.08; \n",
      "FastEstimator-Train: step: 2300; loss: 0.24357724; steps/sec: 61.3; \n",
      "FastEstimator-Train: step: 2346; epoch: 6; epoch_time: 6.57 sec; \n",
      "FastEstimator-Eval: step: 2346; epoch: 6; loss: 0.39285892; min_loss: 0.39232534; since_best: 3; accuracy: 0.8357282665775528; \n",
      "FastEstimator-Train: step: 2400; loss: 0.08471558; steps/sec: 56.66; \n",
      "FastEstimator-Train: step: 2500; loss: 0.20877948; steps/sec: 60.78; \n",
      "FastEstimator-Train: step: 2600; loss: 0.09914401; steps/sec: 61.27; \n",
      "FastEstimator-Train: step: 2700; loss: 0.15458922; steps/sec: 60.94; \n",
      "FastEstimator-Train: step: 2737; epoch: 7; epoch_time: 6.53 sec; \n",
      "FastEstimator-Eval: step: 2737; epoch: 7; loss: 0.43396476; min_loss: 0.39232534; since_best: 4; accuracy: 0.8326729364586815; \n",
      "FastEstimator-Train: step: 2800; loss: 0.16790089; steps/sec: 56.49; \n",
      "FastEstimator-Train: step: 2900; loss: 0.09017545; steps/sec: 60.99; \n",
      "FastEstimator-Train: step: 3000; loss: 0.06604583; steps/sec: 61.62; \n",
      "FastEstimator-Train: step: 3100; loss: 0.2692815; steps/sec: 61.39; \n",
      "FastEstimator-Train: step: 3128; epoch: 8; epoch_time: 6.52 sec; \n",
      "FastEstimator-Eval: step: 3128; epoch: 8; loss: 0.47958812; min_loss: 0.39232534; since_best: 5; accuracy: 0.8260371413567575; \n",
      "FastEstimator-Train: step: 3200; loss: 0.12287539; steps/sec: 56.58; \n",
      "FastEstimator-Train: step: 3300; loss: 0.16652104; steps/sec: 62.04; \n",
      "FastEstimator-Train: step: 3400; loss: 0.08797251; steps/sec: 59.71; \n",
      "FastEstimator-Train: step: 3500; loss: 0.08476864; steps/sec: 60.8; \n",
      "FastEstimator-Train: step: 3519; epoch: 9; epoch_time: 6.56 sec; \n",
      "FastEstimator-Eval: step: 3519; epoch: 9; loss: 0.51876205; min_loss: 0.39232534; since_best: 6; accuracy: 0.824270778631785; \n",
      "FastEstimator-Train: step: 3600; loss: 0.14876236; steps/sec: 56.08; \n",
      "FastEstimator-Train: step: 3700; loss: 0.11151114; steps/sec: 60.72; \n",
      "FastEstimator-Train: step: 3800; loss: 0.05140955; steps/sec: 60.18; \n",
      "FastEstimator-Train: step: 3900; loss: 0.062084932; steps/sec: 59.42; \n",
      "FastEstimator-Train: step: 3910; epoch: 10; epoch_time: 6.62 sec; \n",
      "FastEstimator-Eval: step: 3910; epoch: 10; loss: 0.5560739; min_loss: 0.39232534; since_best: 7; accuracy: 0.831049792333031; \n",
      "FastEstimator-Finish: step: 3910; total_time: 87.54 sec; model_lr: 0.001; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inferencing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inferencing, first we have to load the trained model weights. We saved model weights with minimum loss and we will load the weights using <i>fe.build()</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from /tmp/tmp69qyfzvm/model_best_loss.pt\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_best_loss.pt'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "trained_model = fe.build(model_fn=lambda: ReviewSentiment(), weights_path=model_path, optimizer_fn=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get any random sequence and compare the prediction with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth is:  0\n"
     ]
    }
   ],
   "source": [
    "selected_idx = np.random.randint(10000)\n",
    "print(\"Ground truth is: \",eval_data[selected_idx]['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data dictionary for the inference. <i>Transform()</i> function in Pipeline and Network applies all the operations on the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data = {\"x\":eval_data[selected_idx]['x'], \"y\":eval_data[selected_idx]['y']}\n",
    "data = pipeline.transform(infer_data, mode=\"infer\")\n",
    "data = network.transform(data, mode=\"infer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, pass the model and data to the <i>feed_forward</i> for the inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the input sequence:  0.30634004\n"
     ]
    }
   ],
   "source": [
    "prediction = feed_forward(trained_model, data['x'], training=False)\n",
    "print(\"Prediction for the input sequence: \",np.array(prediction.detach())[0][0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "fastestimator",
   "language": "python",
   "name": "fastestimator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
